{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T16:39:15.587819",
     "start_time": "2016-12-13T16:39:02.804368"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle\n",
    "from os.path import join\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:24.330296",
     "start_time": "2016-12-13T15:27:24.324589"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:24.499994",
     "start_time": "2016-12-13T15:27:24.448509"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main dataframe with aggregated Linkedin, Github and Hacker News data\n"
     ]
    }
   ],
   "source": [
    "print('Loading main dataframe with aggregated Linkedin, Github and Hacker News data')\n",
    "\n",
    "inputfile_path = join('/Users/','Toavina','githubdata','11.getting_linkedin_data','4.pickles','merged_df.pkl')\n",
    "\n",
    "main_df = _pickle.load(open(inputfile_path,'rb'))\n",
    "\n",
    "# Change below if they have been changed in previous script\n",
    "max_jobs = 6\n",
    "max_edu = 5\n",
    "\n",
    "# Education points for use in classifying degrees\n",
    "edu_points = {'phd':7,\n",
    "             'master':6,\n",
    "             'bachelor':5,\n",
    "             'associate':4,\n",
    "             'certificate':3,\n",
    "             'diploma':2,\n",
    "             'school':1,\n",
    "             'unknown':1}\n",
    "\n",
    "# Cutoff dates for final table\n",
    "min_date = '2012-12-31'\n",
    "max_date = '2016-12-31'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T14:00:08.729833",
     "start_time": "2016-12-11T14:00:08.727555"
    }
   },
   "source": [
    "# 2. Creating timeseries dataframe for better charting and analysis user by user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Github events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:24.974432",
     "start_time": "2016-12-13T15:27:24.835352"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up functions to create time-series-index for Github events per user\n",
      "\n",
      "Creating time series of Github events\n",
      "Adding aggregate Github event columns, equal weights and personalised weights\n"
     ]
    }
   ],
   "source": [
    "print('Setting up functions to create time-series-index for Github events per user')\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def select_indiv_eventcol(df,event_type,loc,weight=1):\n",
    "    \"\"\"- Selects columns for number of events for selected event type\n",
    "    - df must be a dataframe containing tuples for the relevant columns,\n",
    "    event_type can be one of the following:\n",
    "    {'CreateEvent', 'PushEvent', 'GollumEvent',\n",
    "    'PullRequestReviewCommentEvent', 'DeleteEvent',\n",
    "    'PullRequestEvent', 'GistEvent', 'PublicEvent'}\n",
    "    - Weight weighs that particular event by a certain factor\n",
    "    - Returns a dataframe with the relevant columns for the event type\n",
    "    weighed by the weight factor\n",
    "    \"\"\"\n",
    "    \n",
    "    # Store username for later aggregation\n",
    "    gh_username = df['inferred_ghuser_copy'][loc]\n",
    "    \n",
    "    # Gets a list of column names which are tuples\n",
    "    col_list = [(index, col[0]) for index, col in enumerate(df.columns)\n",
    "            if type(col) is tuple]\n",
    "\n",
    "    # Returns a list of indices for the relevant event\n",
    "    relevant_index = [col[0] for col in col_list if event_type in col[1]]\n",
    "\n",
    "    # Returns relevant columns with values multiplied by the weight\n",
    "    df = df.iloc[loc,relevant_index] * weight\n",
    "    \n",
    "    # Take only the timeseries from the index\n",
    "    df.index = df.index.map(lambda x: x[1])\n",
    "    \n",
    "    return df.rename(event_type+'_'+gh_username)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def agg_eventcols(df, col_list_weight,loc,colname):\n",
    "    \"\"\"Takes a dataframe df as the first argument, and a list of tuples of the\n",
    "    form [(event_type, weight)] to return an aggregated dataframe that sums\n",
    "    the frequencies of the event types weighted by the weight factor\n",
    "    \"\"\"\n",
    "    gh_username = df['inferred_ghuser_copy'][loc]\n",
    "    \n",
    "    event_cols = [select_indiv_eventcol(df, event_type,loc, weight) for event_type, weight in \\\n",
    "    col_list_weight]\n",
    "\n",
    "    event_cols = reduce(lambda x,y: x+y, event_cols)\n",
    "\n",
    "    return event_cols.rename(colname+'_'+gh_username)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# list of event types to process to add to each user\n",
    "event_types = ['CreateEvent', 'PushEvent', 'GollumEvent',\n",
    "    'PullRequestReviewCommentEvent', 'DeleteEvent',\n",
    "    'PullRequestEvent', 'GistEvent', 'PublicEvent']\n",
    "\n",
    "\n",
    "# Weights for creating aggregate time series\n",
    "equal_weights = [('CreateEvent', 1), \n",
    "                 ('PushEvent', 1),\n",
    "                 ('DeleteEvent', 1),\n",
    "                 ('GistEvent', 1),\n",
    "                 ('GollumEvent', 1),\n",
    "                 ('PublicEvent', 1),\n",
    "                 ('PullRequestEvent', 1),\n",
    "                 ('PullRequestReviewCommentEvent', 1)\n",
    "                ]\n",
    "    \n",
    "perso_weight_list = [('CreateEvent', 2),\n",
    "                      ('PushEvent', 1),\n",
    "                      ('DeleteEvent', 2),\n",
    "                      ('GistEvent', 1),\n",
    "                      ('GollumEvent', 1),\n",
    "                      ('PublicEvent', 2),\n",
    "                      ('PullRequestEvent', 1),\n",
    "                      ('PullRequestReviewCommentEvent', 1)\n",
    "                     ]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\nCreating time series of Github events')\n",
    "user0_ghevents = [select_indiv_eventcol(main_df,event,0,1) for event in event_types]\n",
    "user0_ghevents = pd.concat(user0_ghevents, axis=1)\n",
    "\n",
    "print('Adding aggregate Github event columns, equal weights and personalised weights')\n",
    "aggevent_equalcol = agg_eventcols(main_df,equal_weights,0,'AggEventsEqual')\n",
    "aggevent_weightedcol = agg_eventcols(main_df,perso_weight_list,0,'AggEventsWeighted')\n",
    "user0_ghevents = pd.concat([user0_ghevents,aggevent_equalcol,aggevent_weightedcol], axis=1)\n",
    "\n",
    "# Change at the end as need to add level\n",
    "# user0_ghevents.columns = user0_ghevents.columns.str.split('_', expand=True)\n",
    "# user0_ghevents = user0_ghevents.reorder_levels([1,0], axis=1)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adding Hacker News Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:25.156076",
     "start_time": "2016-12-13T15:27:25.120948"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Hacker News Posts\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def create_hn_post_series(df):\n",
    "    \"\"\"Creates a series containing Hacker News Posts\"\"\"\n",
    "    \n",
    "    posted_dict = {}\n",
    "    username = df['inferred_ghuser_copy'][0]\n",
    "    \n",
    "    for date in df['dates_posted'][0]:\n",
    "        posted_dict[date] = np.int32(1)\n",
    "        \n",
    "    hn_series = pd.Series(posted_dict)\n",
    "    \n",
    "    return hn_series.rename('HNPosts' + '_' + username)\n",
    "\n",
    "\n",
    "def merge_hn_ghevents(ghevents_df,hn_df):\n",
    "    \"\"\"Merges above HN series with user dataframe\"\"\"\n",
    "    \n",
    "    new_df = ghevents_df.join(hn_df)\n",
    "    \n",
    "    new_df[[col for col in new_df.columns if 'HNPosts' in col]] = \\\n",
    "    new_df[[col for col in new_df.columns if 'HNPosts' in col]].fillna(value=0)\n",
    "    \n",
    "    return new_df.astype('int32')\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print('Adding Hacker News Posts')\n",
    "hn0_series = create_hn_post_series(main_df)\n",
    "user0_ghevents = merge_hn_ghevents(user0_ghevents,hn0_series)\n",
    "\n",
    "# posted_dict = {}\n",
    "# username = main_df['inferred_ghuser_copy'][0]\n",
    "# for each in main_df['dates_posted'][0]:\n",
    "#     posted_dict[each] = np.int32(1)\n",
    "# hn_series = pd.Series(posted_dict)\n",
    "# hn_series = hn_series.rename('HNPosts_{}'.format(username))\n",
    "\n",
    "# user0_ghevents = user0_ghevents.join(hn_series)\n",
    "\n",
    "# user0_ghevents['HNPosts_{}'.format(username)] = user0_ghevents['HNPosts_{}'.format(username)].fillna(value=0)\n",
    "\n",
    "# user0_ghevents['HNPosts_{}'.format(username)] = user0_ghevents['HNPosts_{}'.format(username)].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Adding Experiences Start Dates, End Dates by Type & with Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:25.552479",
     "start_time": "2016-12-13T15:27:25.406859"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding experiences (job and education) with start and end dates\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def create_exp_ts(df,loc):\n",
    "    \"\"\"Creates an experience time-series dataframe with four columns for job and education starts and ends\"\"\"\n",
    "    \n",
    "    ghusername = df['inferred_ghuser_copy'][loc]\n",
    "    \n",
    "    user_jobstart_dict = defaultdict(list)\n",
    "    user_jobend_dict = defaultdict(list)\n",
    "    user_edustart_dict = defaultdict(list)\n",
    "    user_eduend_dict = defaultdict(list)\n",
    "    user_expstart_dict = defaultdict(list)\n",
    "    user_expend_dict = defaultdict(list)\n",
    "    \n",
    "    for event in df['all_exp'][loc]:\n",
    "        \n",
    "        user_expstart_dict[event['dates'][0]].append(event)\n",
    "        user_expend_dict[event['dates'][1]].append(event)\n",
    "        \n",
    "        if event['exp_type'] == 'job':\n",
    "            user_jobstart_dict[event['dates'][0]].append(event)\n",
    "            user_jobend_dict[event['dates'][1]].append(event)\n",
    "        \n",
    "        else:\n",
    "            user_edustart_dict[event['dates'][0]].append(event)\n",
    "            user_eduend_dict[event['dates'][1]].append(event)\n",
    "            \n",
    "    user_expstart_df = pd.DataFrame(pd.Series(user_expstart_dict).rename('ExpStart_{}'.format(ghusername)))\n",
    "    user_expend_df = pd.DataFrame(pd.Series(user_expend_dict).rename('ExpEnd_{}'.format(ghusername)))\n",
    "    user_jobstart_df = pd.DataFrame(pd.Series(user_jobstart_dict).rename('JobStart_{}'.format(ghusername)))\n",
    "    user_jobend_df = pd.DataFrame(pd.Series(user_jobend_dict).rename('JobEnd_{}'.format(ghusername)))\n",
    "    user_edustart_df = pd.DataFrame(pd.Series(user_edustart_dict).rename('EduStart_{}'.format(ghusername)))\n",
    "    user_eduend_df = pd.DataFrame(pd.Series(user_eduend_dict).rename('EduEnd_{}'.format(ghusername)))\n",
    "    \n",
    "    user_allexp = pd.concat([user_jobstart_df,user_jobend_df,\n",
    "                            user_edustart_df,user_eduend_df,\n",
    "                            user_expstart_df,user_expend_df], axis = 1)\n",
    "    \n",
    "    return user_allexp\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print('Adding experiences (job and education) with start and end dates')\n",
    "user0_allexp = pd.concat([user0_ghevents,create_exp_ts(main_df,0)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:25.646876",
     "start_time": "2016-12-13T15:27:25.564557"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_numexp(exp_df, maindf, userloc):\n",
    "    \"\"\"Gets the number of experiences for the user and returns columns with the relevant jobs and \n",
    "    educational attainments\"\"\"\n",
    "    \n",
    "    # Use global max_jobs and max_edu variables\n",
    "    global max_jobs, max_edu\n",
    "    \n",
    "    # Get the username to append to each column for final dataframe\n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    \n",
    "    # Calculate the number of experiences to calculate what to add \n",
    "    num_jobs = len([cell for cell in exp_df['JobStart_{}'.format(ghusername)] if pd.notnull(cell)])\n",
    "    num_edu = len([cell for cell in exp_df['EduStart_{}'.format(ghusername)] if pd.notnull(cell)])\n",
    "    num_exp = num_jobs + num_edu\n",
    "    \n",
    "    diff_jobs = max_jobs - num_jobs\n",
    "    diff_edu = max_edu - num_edu\n",
    "    diff_exp = diff_jobs + diff_edu\n",
    "    \n",
    "    # List the cells that are relevant to get the data from\n",
    "    jobs_list = [cell for cell in exp_df['JobStart_{}'.format(ghusername)] if pd.notnull(cell)]\n",
    "    edu_list = [cell for cell in exp_df['EduStart_{}'.format(ghusername)] if pd.notnull(cell)]\n",
    "    exp_list = jobs_list + edu_list\n",
    "    \n",
    "    # Create relevant columns to populate in the dataframe\n",
    "    for j in range(max_jobs):\n",
    "        exp_df['JobExp{}_{}'.format(str(j),ghusername)] = np.nan\n",
    "        exp_df['JobExp{}_{}'.format(str(j),ghusername)] = \\\n",
    "        exp_df['JobExp{}_{}'.format(str(j),ghusername)].astype(object)\n",
    "        \n",
    "    for e in range(max_edu):\n",
    "        exp_df['EduExp{}_{}'.format(str(e),ghusername)] = np.nan\n",
    "        exp_df['EduExp{}_{}'.format(str(e),ghusername)] = \\\n",
    "        exp_df['EduExp{}_{}'.format(str(e),ghusername)].astype(object)\n",
    "    \n",
    "    # Get the index to locate each relevant bit of information\n",
    "    ts_index = exp_df.index\n",
    "    \n",
    "    \n",
    "    # Jobs -----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Populate the new columns with the relevant experience\n",
    "    for j in range(num_jobs):\n",
    "        for date in ts_index:\n",
    "            # Create the relevant cells if the date index is within the beginning and start dates\n",
    "            if (jobs_list[j][0]['dates'][0] <= date) & (jobs_list[j][0]['dates'][1] >= date):\n",
    "                exp_df.set_value(date,'JobExp{}_{}'.format(str(j),ghusername),jobs_list[j][0])\n",
    "    \n",
    "    # Education -----------------------------------------------------------------------------------------------   \n",
    "    \n",
    "    # Populate the new columns with the relevant experience\n",
    "    for j in range(num_edu):\n",
    "        for date in ts_index:\n",
    "            # Create the relevant cells if the date index is within the beginning and start dates\n",
    "            if (edu_list[j][0]['dates'][0] <= date) and (edu_list[j][0]['dates'][1] >= date):\n",
    "                exp_df.set_value(date,'EduExp{}_{}'.format(str(j),ghusername), edu_list[j][0])\n",
    "                \n",
    "\n",
    "    return exp_df\n",
    "    \n",
    "# --------------------------------------------------\n",
    "\n",
    "user0_allexp = get_numexp(user0_allexp,main_df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:26.385880",
     "start_time": "2016-12-13T15:27:25.698199"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explode_exp_info(row, maindf, userloc):\n",
    "    \"Explodes the information from each job and education cell. To be applied to each row of the experience dataframe\"\n",
    "    global max_edu, max_jobs\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    \n",
    "    for i in range(max_jobs):\n",
    "        row['JobExpDates{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpDesc{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpInstitution{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpInstitutionType{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpOverallTenure{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpTitle{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpTitleType{}_{}'.format(str(i),ghusername)] = None\n",
    "        \n",
    "    for i in range(max_edu):\n",
    "        row['EduExpDates{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpDesc{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpInstitution{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpInstitutionType{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpOverallTenure{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpTitle{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpTitleType{}_{}'.format(str(i),ghusername)] = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(max_jobs):\n",
    "        if pd.notnull(row['JobExp{}_{}'.format(str(i),ghusername)]):\n",
    "            \n",
    "            row['JobExpDates{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['dates']\n",
    "            \n",
    "            row['JobExpDesc{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['desc']\n",
    "            \n",
    "            row['JobExpInstitution{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['institution']\n",
    "            \n",
    "            row['JobExpInstitutionType{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['institution_type']\n",
    "            \n",
    "            row['JobExpOverallTenure{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['tenure']\n",
    "            \n",
    "            row['JobExpOverallTenure{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['tenure']\n",
    "            \n",
    "            row['JobExpTitle{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['title']\n",
    "            \n",
    "            row['JobExpTitleType{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['title_type']\n",
    "           \n",
    "        \n",
    "    for i in range(max_edu):\n",
    "        if pd.notnull(row['EduExp{}_{}'.format(str(i),ghusername)]):\n",
    "\n",
    "            row['EduExpDates{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['dates']\n",
    "\n",
    "            row['EduExpDesc{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['desc']\n",
    "\n",
    "            row['EduExpInstitution{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['institution']\n",
    "\n",
    "            row['EduExpInstitutionType{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['institution_type']\n",
    "\n",
    "            row['EduExpOverallTenure{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['tenure']\n",
    "\n",
    "            row['EduExpOverallTenure{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['tenure']\n",
    "\n",
    "            row['EduExpTitle{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['title']\n",
    "\n",
    "            row['EduExpTitleType{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['title_type']\n",
    "            \n",
    "    return row\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "user0_allexp = user0_allexp.apply(explode_exp_info, args=(main_df,0), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:26.390956",
     "start_time": "2016-12-13T15:27:26.387793"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user0_allexp['Index'] = user0_allexp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T16:27:50.390563",
     "start_time": "2016-12-13T16:27:50.194478"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user0_allexp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69e66621c2cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# -------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0muser0_allexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_more_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser0_allexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'user0_allexp' is not defined"
     ]
    }
   ],
   "source": [
    "def get_more_features(exp_df, maindf, userloc):\n",
    "    \"\"\"Extract more features - tenure, whether employed, in education, number of current job titles...\"\"\"\n",
    "    global max_jobs, max_edu\n",
    "\n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "\n",
    "    ts_index = exp_df.index\n",
    "\n",
    "    # Create tenure columns\n",
    "    for i in range(max_jobs):\n",
    "        exp_df['JobExpCurrentTenure{}_{}'.format(str(i), ghusername)] = np.nan\n",
    "        exp_df['JobExpCurrentTenure{}_{}'.format(str(\n",
    "            i), ghusername)] = exp_df['JobExpCurrentTenure{}_{}'.format(\n",
    "                str(i), ghusername)].astype(object)\n",
    "\n",
    "    # Calculate tenure for each job\n",
    "    for i in range(max_jobs):\n",
    "        for date in ts_index:\n",
    "            if np.any(\n",
    "                    pd.notnull(exp_df.ix[date, 'JobExpDates{}_{}'.format(\n",
    "                        str(i), ghusername)])):\n",
    "                exp_df.set_value(\n",
    "                    date,\n",
    "                    'JobExpCurrentTenure{}_{}'.format(str(i), ghusername),\n",
    "                    date - exp_df.\n",
    "                    ix[date, 'JobExpDates{}_{}'.format(str(i), ghusername)][0])\n",
    "                \n",
    "                \n",
    "    # Calculate number of jobs, education and total experiences at each date\n",
    "    \n",
    "    for date in ts_index:\n",
    "        exp_df.ix[date,'NumCurrentJobs_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('JobExpInstitution\\d', col)]].count())\n",
    "        \n",
    "        exp_df.ix[date,'NumCurrentEdu_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('EduExpInstitution\\d', col)]].count())\n",
    "        \n",
    "        exp_df.ix[date,'NumCurrentJobsAndEdu_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('EduExpInstitution\\d', col)]].count()) + \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('JobExpInstitution\\d', col)]].count())\n",
    "        \n",
    "    \n",
    "    # Create EmploymentStatus, EducationStatus, NEET Status\n",
    "    \n",
    "    for date in ts_index:\n",
    "        if exp_df.ix[date,'NumCurrentJobs_{}'.format(ghusername)] == 0:\n",
    "            exp_df.ix[date,'EmploymentStatus_{}'.format(ghusername)] = 0\n",
    "        else:\n",
    "            exp_df.ix[date,'EmploymentStatus_{}'.format(ghusername)] = 1\n",
    "            \n",
    "    for date in ts_index:\n",
    "        if exp_df.ix[date,'NumCurrentEdu_{}'.format(ghusername)] == 0:\n",
    "            exp_df.ix[date,'StudyingStatus_{}'.format(ghusername)] = 0\n",
    "        else:\n",
    "            exp_df.ix[date,'StudyingStatus_{}'.format(ghusername)] = 1\n",
    "            \n",
    "    for date in ts_index:\n",
    "        if exp_df.ix[date,'NumCurrentJobsAndEdu_{}'.format(ghusername)] == 0:\n",
    "            exp_df.ix[date,'NEET_{}'.format(ghusername)] = 1\n",
    "        else:\n",
    "            exp_df.ix[date,'NEET_{}'.format(ghusername)] = 0\n",
    "            \n",
    "    \n",
    "    # Create a status flag for a new job and for an end of jobs\n",
    "    \n",
    "    for date in ts_index:\n",
    "        exp_df.ix[date,'NewJobFlag_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('JobStart', col)]].count())\n",
    "        \n",
    "    for date in ts_index:\n",
    "        exp_df.ix[date,'EndJobFlag_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('JobEnd', col)]].count())\n",
    "    \n",
    "    for date in ts_index:\n",
    "        exp_df.ix[date,'StartEduFlag_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('EduStart', col)]].count())\n",
    "        \n",
    "    for date in ts_index:\n",
    "        exp_df.ix[date,'EndEduFlag_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('EduEnd', col)]].count())\n",
    "        \n",
    "\n",
    "    return exp_df\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "user0_allexp = get_more_features(user0_allexp,main_df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:27.403108",
     "start_time": "2016-12-13T15:27:27.394131"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cum_jobs_edu_todate(exp_df,maindf,userloc):\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    exp_df['CumJobsToDate_{}'.format(ghusername)] = exp_df['NewJobFlag_{}'.format(ghusername)].cumsum()\n",
    "    \n",
    "    exp_df['CumEduToDate_{}'.format(ghusername)] = exp_df['StartEduFlag_{}'.format(ghusername)].cumsum()\n",
    "    \n",
    "# -------------------------------------------------------------\n",
    "\n",
    "cum_jobs_edu_todate(user0_allexp,main_df,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:28.095230",
     "start_time": "2016-12-13T15:27:27.405089"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def idenfify_highest_degree(exp_df,maindf,userloc):\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    ts_index = exp_df.index # to change back if doesn't work\n",
    "    \n",
    "    # Creates value to initialize best edu_rating\n",
    "    highest_edu_rating = 0\n",
    "    highest_degree = 'unknown'\n",
    "    highest_institution = 'unknown'\n",
    "    highest_institution_type = 'unknown'\n",
    "    highest_title = 'unknown'\n",
    "    \n",
    "\n",
    "    # Set the first value of the degree to minimum above before iteration\n",
    "    exp_df.ix[0,'HighestDegree_{}'.format(ghusername)] = highest_degree\n",
    "    exp_df.ix[0,'HighestInstitution_{}'.format(ghusername)] = highest_institution\n",
    "    exp_df.ix[0,'HighestInstitutionType_{}'.format(ghusername)] = highest_institution_type\n",
    "    exp_df.ix[0,'HighestDegreeDesc_{}'.format(ghusername)] = highest_title\n",
    "    exp_df.ix[0,'HighestDegreeStartDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'HighestDegreeEndDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'HighestDegreeTimeSinceStartDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'HighestDegreeTimeSinceEndDate_{}'.format(ghusername)] = None\n",
    "    \n",
    "    \n",
    "    # Iterate through each row and compare if a higher degree has been achieved\n",
    "    for i in range(len(ts_index)):\n",
    "        \n",
    "        # Ignore blank rows without new education status\n",
    "        if np.any(pd.notnull(exp_df.ix[i,'EduStart_{}'.format(ghusername)])):\n",
    "                    \n",
    "            # Iterate through each education item and update best if better than what is there\n",
    "            for edu in exp_df.ix[i,'EduStart_{}'.format(ghusername)]:\n",
    "                edu_rating = edu_points[edu['title_type']]\n",
    "                # Ignore equal education rating and only update if better\n",
    "                if edu_rating >= highest_edu_rating:\n",
    "                    highest_edu_rating = edu_rating\n",
    "                    highest_degree = edu['title_type']\n",
    "                    highest_institution = edu['institution']\n",
    "                    highest_institution_type = edu['institution_type']\n",
    "                    highest_title = edu['title']                    \n",
    "                    highest_degree_start_date = edu['dates'][0]\n",
    "                    highest_degree_end_date = edu['dates'][1]\n",
    "            \n",
    "            exp_df.ix[i,'HighestDegree_{}'.format(ghusername)] = highest_degree\n",
    "            exp_df.ix[i,'HighestInstitution_{}'.format(ghusername)] = highest_institution\n",
    "            exp_df.ix[i,'HighestInstitutionType_{}'.format(ghusername)] = highest_institution_type\n",
    "            exp_df.ix[i,'HighestDegreeDesc_{}'.format(ghusername)] = highest_title            \n",
    "            exp_df.ix[i,'HighestDegreeStartDate_{}'.format(ghusername)] = highest_degree_start_date\n",
    "            exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)] = highest_degree_end_date\n",
    "            \n",
    "            # Start date becomes relevant once entry is populated\n",
    "            exp_df.ix[i,'HighestDegreeTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "            exp_df.index[i] - exp_df.ix[i,'HighestDegreeStartDate_{}'.format(ghusername)]\n",
    "            \n",
    "            # End date only relevant once end date is smaller than the start date - test for that,\n",
    "            # otherwise stays none\n",
    "            \n",
    "            if exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)] < exp_df.index[i]:\n",
    "                exp_df.ix[i,'HighestDegreeTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.index[i] - exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)]\n",
    "            \n",
    "        else:\n",
    "            # Special case for first row\n",
    "            if i == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                # Set the degree to the previous value in the time series\n",
    "                exp_df.ix[i,'HighestDegree_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestDegree_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'HighestInstitution_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestInstitution_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'HighestInstitutionType_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestInstitutionType_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'HighestDegreeDesc_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestDegreeDesc_{}'.format(ghusername)]\n",
    "                                    \n",
    "                exp_df.ix[i,'HighestDegreeStartDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestDegreeStartDate_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestDegreeEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "                if exp_df.ix[i-1,'HighestDegree_{}'.format(ghusername)] != 'unknown':\n",
    "                    exp_df.ix[i,'HighestDegreeTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "                    exp_df.index[i] - exp_df.ix[i,'HighestDegreeStartDate_{}'.format(ghusername)]\n",
    "                \n",
    "                    if exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)] < exp_df.index[i]:\n",
    "                        exp_df.ix[i,'HighestDegreeTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "                        exp_df.index[i] - exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "    \n",
    "    return exp_df\n",
    "        \n",
    "# ----------------------------------------------------------------\n",
    "    \n",
    "user0_allexp = idenfify_highest_degree(user0_allexp,main_df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:28.421326",
     "start_time": "2016-12-13T15:27:28.096948"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def idenfify_bootcamps(exp_df,maindf,userloc):\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    ts_index = exp_df['Index']\n",
    "    \n",
    "    # Creates value to initialize best edu_rating\n",
    "    bootcamp_institution = None\n",
    "    bootcamp_dates = None\n",
    "    time_since_bootcamp_start = None\n",
    "    time_since_bootcamp_end = None\n",
    "    \n",
    "    # Set the first value of the degree to above before iteration\n",
    "    exp_df.ix[0,'MostRecentBootCamp_{}'.format(ghusername)] = bootcamp_institution\n",
    "    exp_df.ix[0,'BootCampDates_{}'.format(ghusername)] = bootcamp_dates\n",
    "    exp_df.ix[0,'TimeSinceBootCampStart_{}'.format(ghusername)] = time_since_bootcamp_start\n",
    "    exp_df.ix[0,'TimeSinceBootCampEnd_{}'.format(ghusername)] = time_since_bootcamp_end\n",
    "    \n",
    "    # Iterate through each row and see if a bootcamp has been taken\n",
    "    for i in range(len(ts_index)):\n",
    "        \n",
    "        # Ignore blank rows without new education status\n",
    "        if np.any(pd.notnull(exp_df.ix[i,'ExpStart_{}'.format(ghusername)])):\n",
    "                    \n",
    "            # Iterate through each education item and update best if better than what is there\n",
    "            for exp in exp_df.ix[i,'ExpStart_{}'.format(ghusername)]:\n",
    "                # Ignore equal education rating and only update if better\n",
    "                if exp['institution_type'] == 'bootcamp' or exp['title_type'] == 'certificate':\n",
    "                    bootcamp_institution = exp['institution']\n",
    "                    bootcamp_dates = exp['dates']\n",
    "                    time_since_bootcamp_start = ts_index[i] - bootcamp_dates[0]\n",
    "                    time_since_bootcamp_end = ts_index[i] - bootcamp_dates[1]\n",
    "            \n",
    "            exp_df.ix[i,'MostRecentBootCamp_{}'.format(ghusername)] = bootcamp_institution\n",
    "            exp_df.ix[i,'BootCampDates_{}'.format(ghusername)] = bootcamp_dates\n",
    "            exp_df.ix[i,'TimeSinceBootCampStart_{}'.format(ghusername)] = time_since_bootcamp_start\n",
    "            exp_df.ix[i,'TimeSinceBootCampEnd_{}'.format(ghusername)] = time_since_bootcamp_end\n",
    "            \n",
    "        else:\n",
    "            # Special case for first row\n",
    "            if i == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                # Set the degree to the previous value in the time series\n",
    "                exp_df.ix[i,'MostRecentBootCamp_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'MostRecentBootCamp_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'BootCampDates_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'BootCampDates_{}'.format(ghusername)]\n",
    "                \n",
    "                if np.any(pd.isnull(exp_df.ix[i-1,'MostRecentBootCamp_{}'.format(ghusername)])):\n",
    "                                    \n",
    "                                    exp_df.ix[i,'TimeSinceBootCampStart_{}'.format(ghusername)] = \\\n",
    "                                    exp_df.ix[i-1,'TimeSinceBootCampStart_{}'.format(ghusername)]\n",
    "                                    \n",
    "                                    exp_df.ix[i,'TimeSinceBootCampEnd_{}'.format(ghusername)] = \\\n",
    "                                    exp_df.ix[i-1,'TimeSinceBootCampEnd_{}'.format(ghusername)]\n",
    "                                    \n",
    "                else:\n",
    "                                    \n",
    "                    exp_df.ix[i,'TimeSinceBootCampStart_{}'.format(ghusername)] = \\\n",
    "                    ts_index[i] - exp_df.ix[i,'BootCampDates_{}'.format(ghusername)][0]\n",
    "\n",
    "                    exp_df.ix[i,'TimeSinceBootCampEnd_{}'.format(ghusername)] = \\\n",
    "                    ts_index[i] - exp_df.ix[i,'BootCampDates_{}'.format(ghusername)][1]\n",
    "    \n",
    "    return exp_df\n",
    "        \n",
    "# ----------------------------------------------------------------\n",
    "user0_allexp = idenfify_bootcamps(user0_allexp,main_df,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:29.050012",
     "start_time": "2016-12-13T15:27:28.423033"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def idenfify_recent_job(exp_df,maindf,userloc):\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    ts_index = exp_df['Index']\n",
    "    \n",
    "    # Creates value to initialize best edu_rating\n",
    "    recent_job = 'unknown'\n",
    "    recent_institution = 'unknown'\n",
    "    recent_institution_type = 'unknown'\n",
    "    recent_title = 'unknown'\n",
    "    recent_title_type = 'unknown'\n",
    "    \n",
    "\n",
    "    # Set the first value of the degree to minimum above before iteration\n",
    "    exp_df.ix[0,'RecentJob_{}'.format(ghusername)] = recent_job\n",
    "    exp_df.ix[0,'RecentJobInstitution_{}'.format(ghusername)] = recent_institution\n",
    "    exp_df.ix[0,'RecentJobInstitutionType_{}'.format(ghusername)] = recent_institution_type\n",
    "    exp_df.ix[0,'RecentJobDesc_{}'.format(ghusername)] = recent_title\n",
    "    exp_df.ix[0,'RecentJobStartDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'RecentJobEndDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'RecentJobTimeSinceStartDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'RecentJobTimeSinceEndDate_{}'.format(ghusername)] = None\n",
    "    \n",
    "    \n",
    "    # Iterate through each row and compare if a more recent job has been started\n",
    "    for i in range(len(ts_index)):\n",
    "        \n",
    "        # Ignore blank rows without new job status\n",
    "        if np.any(pd.notnull(exp_df.ix[i,'JobStart_{}'.format(ghusername)])):\n",
    "                    \n",
    "            # Iterate through each education item and update best if better than what is there\n",
    "            for job in exp_df.ix[i,'JobStart_{}'.format(ghusername)]:\n",
    "                job_date = job['dates'][0]\n",
    "                # Ignore equal education rating and only update if better\n",
    "                if job_date >= ts_index[0]:\n",
    "                    recent_job = job['title_type']\n",
    "                    recent_institution = job['institution']\n",
    "                    recent_institution_type = job['institution_type']\n",
    "                    recent_title = job['title']                    \n",
    "                    recent_job_start_date = job['dates'][0]\n",
    "                    recent_job_end_date = job['dates'][1]\n",
    "            \n",
    "            exp_df.ix[i,'RecentJob_{}'.format(ghusername)] = recent_job\n",
    "            exp_df.ix[i,'RecentJobInstitution_{}'.format(ghusername)] = recent_institution\n",
    "            exp_df.ix[i,'RecentJobInstitutionType_{}'.format(ghusername)] = recent_institution_type\n",
    "            exp_df.ix[i,'RecentJobDesc_{}'.format(ghusername)] = recent_title            \n",
    "            exp_df.ix[i,'RecentJobStartDate_{}'.format(ghusername)] = recent_job_start_date\n",
    "            exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)] = recent_job_end_date\n",
    "            \n",
    "            # Start date becomes relevant once entry is populated\n",
    "            exp_df.ix[i,'RecentJobTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "            exp_df.ix[i,'Index'] - exp_df.ix[i,'RecentJobStartDate_{}'.format(ghusername)]\n",
    "            \n",
    "            # End date only relevant once end date is smaller than the start date - test for that,\n",
    "            # otherwise stays none\n",
    "            \n",
    "            if exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)] < exp_df.ix[i,'Index']:\n",
    "                exp_df.ix[i,'RecentJobTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i,'Index'] - exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)]\n",
    "            \n",
    "        else:\n",
    "            # Special case for first row\n",
    "            if i == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                # Set the degree to the previous value in the time series\n",
    "                exp_df.ix[i,'RecentJob_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJob_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'RecentJobInstitution_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobInstitution_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'RecentJobInstitutionType_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobInstitutionType_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'RecentJobDesc_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobDesc_{}'.format(ghusername)]\n",
    "                                    \n",
    "                exp_df.ix[i,'RecentJobStartDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobStartDate_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "                if exp_df.ix[i-1,'RecentJob_{}'.format(ghusername)] != 'unknown':\n",
    "                    exp_df.ix[i,'RecentJobTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "                    exp_df.ix[i,'Index'] - exp_df.ix[i,'RecentJobStartDate_{}'.format(ghusername)]\n",
    "                \n",
    "                    if exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)] < exp_df.index[i]:\n",
    "                        exp_df.ix[i,'RecentJobTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "                        exp_df.ix[i,'Index'] - exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "    \n",
    "    return exp_df\n",
    "        \n",
    "# ----------------------------------------------------------------\n",
    "    \n",
    "user0_allexp = idenfify_recent_job(user0_allexp,main_df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:29.373024",
     "start_time": "2016-12-13T15:27:29.051679"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_min_max_tenure(row,maindf,userloc):\n",
    "    \"\"\"Get the minimum tenure of the most recent job - If very low, unlikely to be looking for job\"\"\"\n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    \n",
    "    relevantcols = [col for col in row.index if 'JobExpCurrentTenure' in col]\n",
    "    \n",
    "    # Factor to divide result by to get result in days\n",
    "    divfactor = 3600*24*1000000000\n",
    "    \n",
    "    if pd.isnull(row[relevantcols].values.any()):\n",
    "        row['MinJobTenure_{}'.format(ghusername)] = 0\n",
    "        row['MaxJobTenure_{}'.format(ghusername)] = 0\n",
    "        row['MeanJobTenure_{}'.format(ghusername)] = 0\n",
    "    \n",
    "    else:\n",
    "        row['MinJobTenure_{}'.format(ghusername)] = \\\n",
    "        min([item for item in row[relevantcols] if pd.notnull(item)])/divfactor\n",
    "        \n",
    "        row['MaxJobTenure_{}'.format(ghusername)] = \\\n",
    "        max([item for item in row[relevantcols] if pd.notnull(item)])/divfactor\n",
    "        \n",
    "        row['MeanJobTenure_{}'.format(ghusername)] = \\\n",
    "        np.mean([item for item in row[relevantcols] if pd.notnull(item)])/divfactor\n",
    "        \n",
    "    return row\n",
    "\n",
    "# ----------------------------------------------------------------    \n",
    "\n",
    "user0_allexp = user0_allexp.apply(get_min_max_tenure,args=(main_df,0),axis=1)\n",
    "\n",
    "user0_allexp = user0_allexp.drop('Index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T18:55:21.690020",
     "start_time": "2016-12-11T18:55:21.687815"
    }
   },
   "source": [
    "## 2.4 Adding All Info from Main Dataframe to TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:29.446027",
     "start_time": "2016-12-13T15:27:29.374566"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data0 = pd.DataFrame(main_df[[\n",
    "    'linkedin_name', 'name', 'contact', 'gh_acct_created_at', 'updated_at',\n",
    "    'followers', 'following', 'hireable', 'email', 'inferred_ghuser_copy',\n",
    "    'login', 'github_account', 'hn_username', 'location_hn',\n",
    "    'linkedin_location', 'location_gh', 'company', 'remote', 'can_relocate',\n",
    "    'stack', 'resume', 'links', 'text', 'body', 'bio', 'blog', 'public_gists',\n",
    "    'public_repos'\n",
    "]].loc[0,:]).transpose()\n",
    "\n",
    "user_data0['old_index'] = user_data0.index\n",
    "\n",
    "username = user_data0['inferred_ghuser_copy'][0]\n",
    "\n",
    "user_data0 = user_data0.rename(columns={'linkedin_name':'LinkedInName_{}'.format(username),\n",
    "                           'name': 'Name_{}'.format(username),\n",
    "                           'contact': 'Contact_{}'.format(username),\n",
    "                           'gh_acct_created_at': 'GHAcctCreatedAt_{}'.format(username),\n",
    "                           'updated_at': 'GHAcctUpdatedAt_{}'.format(username),\n",
    "                           'followers': 'GHFollowers_{}'.format(username),\n",
    "                           'following': 'GHFollowing_{}'.format(username),\n",
    "                           'hireable': 'GHHireable_{}'.format(username),\n",
    "                           'email': 'Email_{}'.format(username) ,\n",
    "                           'inferred_ghuser_copy': 'InferredGHUserCopy_{}'.format(username) ,\n",
    "                           'login': 'GHLogin_{}'.format(username),\n",
    "                           'github_account': 'GHAcct_{}'.format(username),\n",
    "                           'hn_username': 'HNUsername_{}'.format(username),\n",
    "                           'location_hn': 'HNLocation_{}'.format(username),\n",
    "                           'linkedin_location': 'LinkedInLocation_{}'.format(username),\n",
    "                           'location_gh': 'GHLocation_{}'.format(username),\n",
    "                           'company': 'GHCompany_{}'.format(username),\n",
    "                           'remote': 'Remote_{}'.format(username),\n",
    "                           'can_relocate': 'CanRelocate_{}'.format(username),\n",
    "                           'stack': 'Stack_{}'.format(username),\n",
    "                           'resume': 'Resume_{}'.format(username),\n",
    "                           'links': 'Links_{}'.format(username),\n",
    "                           'text': 'Text_{}'.format(username),\n",
    "                           'body': 'Body_{}'.format(username),\n",
    "                           'bio': 'Bio_{}'.format(username),\n",
    "                           'blog': 'Blog_{}'.format(username),\n",
    "                           'public_gists': 'PublicGists_{}'.format(username),\n",
    "                           'public_repos': 'PublicRepos_{}'.format(username),\n",
    "                           'old_index': 'OldIndex_{}'.format(username)             \n",
    "                          })\n",
    "\n",
    "user_data0.index = [np.datetime64('2013-12-31')]\n",
    "date_index = pd.date_range('01/31/2013', periods=49, freq='M')\n",
    "user_data0 = pd.concat([user_data0]*49)\n",
    "user_data0.index = date_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:29.493935",
     "start_time": "2016-12-13T15:27:29.447649"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_gh_info(df,maindf,userloc):\n",
    "    \"\"\" Adds time since GH account created\"\"\"\n",
    "    \n",
    "    username = maindf['inferred_ghuser_copy'].loc[userloc]\n",
    "    \n",
    "    month_GH_created = [item for item in df['GHAcctCreatedAt_{}'.format(username)].unique() \\\n",
    "                        if pd.notnull(item)][0].to_period('M').to_timestamp('M')\n",
    "    \n",
    "    df['GHAccountCreationMonthFlag_{}'.format(username)] = 0\n",
    "    \n",
    "    ts_index = df.index\n",
    "    \n",
    "    for date in ts_index:\n",
    "        if month_GH_created == date:\n",
    "            df['GHAccountCreationMonthFlag_{}'.format(username)] =1\n",
    "            \n",
    "        df.ix[date,'TimeSinceGHAccountCreated_{}'.format(username)] = date - month_GH_created\n",
    "        \n",
    "# ------------------------------------\n",
    "\n",
    "add_gh_info(user_data0,main_df,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:29.509437",
     "start_time": "2016-12-13T15:27:29.495489"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_data0 = pd.concat([user0_allexp,user_data0],axis=1)\n",
    "\n",
    "user_data0.columns = user_data0.columns.str.split('_', expand=True)\n",
    "user_data0 = user_data0.reorder_levels([1,0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T15:27:29.515322",
     "start_time": "2016-12-13T15:27:29.511414"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_data0 = user_data0[(user_data0.index > min_date) & (user_data0.index < max_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
