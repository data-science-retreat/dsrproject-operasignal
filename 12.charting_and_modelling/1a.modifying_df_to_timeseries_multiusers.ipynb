{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T17:19:47.091237",
     "start_time": "2016-12-13T17:19:47.086640"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle\n",
    "from os.path import join\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_notebook, tqdm_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T17:23:05.169798",
     "start_time": "2016-12-13T17:23:05.166748"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 500\n",
    "tqdm.pandas(desc='my bar!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T17:19:48.980710",
     "start_time": "2016-12-13T17:19:48.930810"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main dataframe with aggregated Linkedin, Github and Hacker News data\n"
     ]
    }
   ],
   "source": [
    "print('Loading main dataframe with aggregated Linkedin, Github and Hacker News data')\n",
    "\n",
    "inputfile_path = join('/Users/','Toavina','githubdata','11.getting_linkedin_data','4.pickles','merged_df.pkl')\n",
    "\n",
    "savefile_path = join('/Users/','Toavina','githubdata','12.charting_and_modelling','1.pickles','merged_df.pkl')\n",
    "savefile_path_concat = join('/Users/','Toavina','githubdata','12.charting_and_modelling','1.pickles','merged_df_concat.pkl')\n",
    "\n",
    "main_df = _pickle.load(open(inputfile_path,'rb'))\n",
    "\n",
    "# Change below if they have been changed in previous script\n",
    "max_jobs = 6\n",
    "max_edu = 5\n",
    "\n",
    "# Education points for use in classifying degrees\n",
    "edu_points = {'phd':7,\n",
    "             'master':6,\n",
    "             'bachelor':5,\n",
    "             'associate':4,\n",
    "             'certificate':3,\n",
    "             'diploma':2,\n",
    "             'school':1,\n",
    "             'unknown':1}\n",
    "\n",
    "# Cutoff dates for final table\n",
    "min_date = '2012-12-31'\n",
    "max_date = '2016-12-31'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T14:00:08.729833",
     "start_time": "2016-12-11T14:00:08.727555"
    }
   },
   "source": [
    "# 2. Creating timeseries dataframe for better charting and analysis user by user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Github events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T17:20:34.982046",
     "start_time": "2016-12-13T17:19:50.134523"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up functions to create time-series-index for Github events per user\n",
      "\n",
      "Creating time series of Github events\n",
      "Adding aggregate Github event columns, equal weights and personalised weights\n"
     ]
    }
   ],
   "source": [
    "print('Setting up functions to create time-series-index for Github events per user')\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def select_indiv_eventcol(df,event_type,loc,weight=1):\n",
    "    \"\"\"- Selects columns for number of events for selected event type\n",
    "    - df must be a dataframe containing tuples for the relevant columns,\n",
    "    event_type can be one of the following:\n",
    "    {'CreateEvent', 'PushEvent', 'GollumEvent',\n",
    "    'PullRequestReviewCommentEvent', 'DeleteEvent',\n",
    "    'PullRequestEvent', 'GistEvent', 'PublicEvent'}\n",
    "    - Weight weighs that particular event by a certain factor\n",
    "    - Returns a dataframe with the relevant columns for the event type\n",
    "    weighed by the weight factor\n",
    "    \"\"\"\n",
    "    \n",
    "    # Store username for later aggregation\n",
    "    gh_username = df['inferred_ghuser_copy'].iloc[loc]\n",
    "    \n",
    "    # Gets a list of column names which are tuples\n",
    "    col_list = [(index, col[0]) for index, col in enumerate(df.columns)\n",
    "            if type(col) is tuple]\n",
    "\n",
    "    # Returns a list of indices for the relevant event\n",
    "    relevant_index = [col[0] for col in col_list if event_type in col[1]]\n",
    "\n",
    "    # Returns relevant columns with values multiplied by the weight\n",
    "    df = df.iloc[loc,relevant_index] * weight\n",
    "    \n",
    "    # Take only the timeseries from the index\n",
    "    df.index = df.index.map(lambda x: x[1])\n",
    "    \n",
    "    return df.rename(event_type+'_'+gh_username)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def agg_eventcols(df, col_list_weight,loc,colname):\n",
    "    \"\"\"Takes a dataframe df as the first argument, and a list of tuples of the\n",
    "    form [(event_type, weight)] to return an aggregated dataframe that sums\n",
    "    the frequencies of the event types weighted by the weight factor\n",
    "    \"\"\"\n",
    "    gh_username = df['inferred_ghuser_copy'].iloc[loc]\n",
    "    \n",
    "    event_cols = [select_indiv_eventcol(df, event_type,loc, weight) for event_type, weight in \\\n",
    "    col_list_weight]\n",
    "\n",
    "    event_cols = reduce(lambda x,y: x+y, event_cols)\n",
    "\n",
    "    return event_cols.rename(colname+'_'+gh_username)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# list of event types to process to add to each user\n",
    "event_types = ['CreateEvent', 'PushEvent', 'GollumEvent',\n",
    "    'PullRequestReviewCommentEvent', 'DeleteEvent',\n",
    "    'PullRequestEvent', 'GistEvent', 'PublicEvent']\n",
    "\n",
    "\n",
    "# Weights for creating aggregate time series\n",
    "equal_weights = [('CreateEvent', 1), \n",
    "                 ('PushEvent', 1),\n",
    "                 ('DeleteEvent', 1),\n",
    "                 ('GistEvent', 1),\n",
    "                 ('GollumEvent', 1),\n",
    "                 ('PublicEvent', 1),\n",
    "                 ('PullRequestEvent', 1),\n",
    "                 ('PullRequestReviewCommentEvent', 1)\n",
    "                ]\n",
    "    \n",
    "perso_weight_list = [('CreateEvent', 2),\n",
    "                      ('PushEvent', 1),\n",
    "                      ('DeleteEvent', 2),\n",
    "                      ('GistEvent', 1),\n",
    "                      ('GollumEvent', 1),\n",
    "                      ('PublicEvent', 2),\n",
    "                      ('PullRequestEvent', 1),\n",
    "                      ('PullRequestReviewCommentEvent', 1)\n",
    "                     ]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\nCreating time series of Github events')\n",
    "\n",
    "user_ghevents = [[select_indiv_eventcol(main_df,event,number,1) for event in event_types] for number in range(len(main_df))]\n",
    "user_ghevents = [pd.concat(item, axis=1) for item in user_ghevents]    \n",
    "\n",
    "print('Adding aggregate Github event columns, equal weights and personalised weights')\n",
    "\n",
    "aggevent_equalcols = [agg_eventcols(main_df,equal_weights,i,'AggEventsEqual') for i in range(len(main_df))]\n",
    "aggevent_weightedcols = [agg_eventcols(main_df,perso_weight_list,i,'AggEventsWeighted') for i in range(len(main_df))]\n",
    "user_events = [pd.concat([user_ghevents[i],aggevent_equalcols[i],aggevent_weightedcols[i]],\n",
    "                         axis=1) for i in range(len(main_df))]\n",
    "# ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adding Hacker News Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T17:20:38.140093",
     "start_time": "2016-12-13T17:20:34.984098"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Hacker News Posts\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def create_hn_post_series(df,loc):\n",
    "    \"\"\"Creates a series containing Hacker News Posts\"\"\"\n",
    "    \n",
    "    posted_dict = {}\n",
    "    username = df['inferred_ghuser_copy'].iloc[loc]\n",
    "    \n",
    "    for date in df['dates_posted'].iloc[loc]:\n",
    "        posted_dict[date] = np.int32(1)\n",
    "        \n",
    "    hn_series = pd.Series(posted_dict)\n",
    "    \n",
    "    return hn_series.rename('HNPosts' + '_' + username)\n",
    "\n",
    "\n",
    "def merge_hn_ghevents(ghevents_df,hn_df):\n",
    "    \"\"\"Merges above HN series with user dataframe\"\"\"\n",
    "    \n",
    "    new_df = ghevents_df.join(hn_df)\n",
    "    \n",
    "    new_df[[col for col in new_df.columns if 'HNPosts' in col]] = \\\n",
    "    new_df[[col for col in new_df.columns if 'HNPosts' in col]].fillna(value=0)\n",
    "    \n",
    "    return new_df.astype('int32')\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print('Adding Hacker News Posts')\n",
    "hn_series = [create_hn_post_series(main_df,i) for i in range(len(main_df))]\n",
    "user_events = [merge_hn_ghevents(user_events[i],hn_series[i]) for i in range(len(main_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Adding Experiences Start Dates, End Dates by Type & with Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T17:20:46.544198",
     "start_time": "2016-12-13T17:20:38.141700"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding experiences (job and education) with start and end dates\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def create_exp_ts(df,loc):\n",
    "    \"\"\"Creates an experience time-series dataframe with four columns for job and education starts and ends\"\"\"\n",
    "    \n",
    "    ghusername = df['inferred_ghuser_copy'].iloc[loc]\n",
    "    \n",
    "    user_jobstart_dict = defaultdict(list)\n",
    "    user_jobend_dict = defaultdict(list)\n",
    "    user_edustart_dict = defaultdict(list)\n",
    "    user_eduend_dict = defaultdict(list)\n",
    "    user_expstart_dict = defaultdict(list)\n",
    "    user_expend_dict = defaultdict(list)\n",
    "    \n",
    "    try:\n",
    "        for event in df['all_exp'].iloc[loc]:\n",
    "\n",
    "            user_expstart_dict[event['dates'][0]].append(event)\n",
    "            user_expend_dict[event['dates'][1]].append(event)\n",
    "\n",
    "            if event['exp_type'] == 'job':\n",
    "                user_jobstart_dict[event['dates'][0]].append(event)\n",
    "                user_jobend_dict[event['dates'][1]].append(event)\n",
    "\n",
    "            else:\n",
    "                user_edustart_dict[event['dates'][0]].append(event)\n",
    "                user_eduend_dict[event['dates'][1]].append(event)\n",
    "\n",
    "        user_expstart_df = pd.DataFrame(pd.Series(user_expstart_dict).rename('ExpStart_{}'.format(ghusername)))\n",
    "        user_expend_df = pd.DataFrame(pd.Series(user_expend_dict).rename('ExpEnd_{}'.format(ghusername)))\n",
    "        user_jobstart_df = pd.DataFrame(pd.Series(user_jobstart_dict).rename('JobStart_{}'.format(ghusername)))\n",
    "        user_jobend_df = pd.DataFrame(pd.Series(user_jobend_dict).rename('JobEnd_{}'.format(ghusername)))\n",
    "        user_edustart_df = pd.DataFrame(pd.Series(user_edustart_dict).rename('EduStart_{}'.format(ghusername)))\n",
    "        user_eduend_df = pd.DataFrame(pd.Series(user_eduend_dict).rename('EduEnd_{}'.format(ghusername)))\n",
    "\n",
    "        user_allexp = pd.concat([user_jobstart_df,user_jobend_df,\n",
    "                                user_edustart_df,user_eduend_df,\n",
    "                                user_expstart_df,user_expend_df], axis = 1)\n",
    "    except:\n",
    "        user_expstart_dict[np.datetime64('2013-12-31')] = np.nan\n",
    "        user_expend_dict[np.datetime64('2013-12-31')] = np.nan\n",
    "        user_jobstart_dict[np.datetime64('2013-12-31')] = np.nan\n",
    "        user_jobend_dict[np.datetime64('2013-12-31')] = np.nan\n",
    "        user_edustart_dict[np.datetime64('2013-12-31')] = np.nan\n",
    "        user_eduend_dict[np.datetime64('2013-12-31')] = np.nan\n",
    "        \n",
    "        user_expstart_df = pd.DataFrame(pd.Series(user_expstart_dict).rename('ExpStart_{}'.format(ghusername)))\n",
    "        user_expend_df = pd.DataFrame(pd.Series(user_expend_dict).rename('ExpEnd_{}'.format(ghusername)))\n",
    "        user_jobstart_df = pd.DataFrame(pd.Series(user_jobstart_dict).rename('JobStart_{}'.format(ghusername)))\n",
    "        user_jobend_df = pd.DataFrame(pd.Series(user_jobend_dict).rename('JobEnd_{}'.format(ghusername)))\n",
    "        user_edustart_df = pd.DataFrame(pd.Series(user_edustart_dict).rename('EduStart_{}'.format(ghusername)))\n",
    "        user_eduend_df = pd.DataFrame(pd.Series(user_eduend_dict).rename('EduEnd_{}'.format(ghusername)))\n",
    "        \n",
    "        user_allexp = pd.concat([user_jobstart_df,user_jobend_df,\n",
    "                                user_edustart_df,user_eduend_df,\n",
    "                                user_expstart_df,user_expend_df], axis = 1)\n",
    "    \n",
    "    return user_allexp\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print('Adding experiences (job and education) with start and end dates')\n",
    "user_allexp = [pd.concat([user_events[i],create_exp_ts(main_df,i)],axis=1) for i in range(len(main_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T17:20:58.474741",
     "start_time": "2016-12-13T17:20:46.546162"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_numexp(exp_df, maindf, userloc):\n",
    "    \"\"\"Gets the number of experiences for the user and returns columns with the relevant jobs and \n",
    "    educational attainments\"\"\"\n",
    "    \n",
    "    # Use global max_jobs and max_edu variables\n",
    "    global max_jobs, max_edu\n",
    "    \n",
    "    # Get the username to append to each column for final dataframe\n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    \n",
    "    # Calculate the number of experiences to calculate what to add \n",
    "    num_jobs = len([cell for cell in exp_df['JobStart_{}'.format(ghusername)] if np.any(pd.notnull(cell))])\n",
    "    num_edu = len([cell for cell in exp_df['EduStart_{}'.format(ghusername)] if np.any(pd.notnull(cell))])\n",
    "    num_exp = num_jobs + num_edu\n",
    "    \n",
    "    diff_jobs = max_jobs - num_jobs\n",
    "    diff_edu = max_edu - num_edu\n",
    "    diff_exp = diff_jobs + diff_edu\n",
    "    \n",
    "    # List the cells that are relevant to get the data from\n",
    "    jobs_list = [cell for cell in exp_df['JobStart_{}'.format(ghusername)] if np.any(pd.notnull(cell))]\n",
    "    edu_list = [cell for cell in exp_df['EduStart_{}'.format(ghusername)] if np.any(pd.notnull(cell))]\n",
    "    exp_list = jobs_list + edu_list\n",
    "    \n",
    "    # Create relevant columns to populate in the dataframe\n",
    "    for j in range(max_jobs):\n",
    "        exp_df['JobExp{}_{}'.format(str(j),ghusername)] = np.nan\n",
    "        exp_df['JobExp{}_{}'.format(str(j),ghusername)] = \\\n",
    "        exp_df['JobExp{}_{}'.format(str(j),ghusername)].astype(object)\n",
    "        \n",
    "    for e in range(max_edu):\n",
    "        exp_df['EduExp{}_{}'.format(str(e),ghusername)] = np.nan\n",
    "        exp_df['EduExp{}_{}'.format(str(e),ghusername)] = \\\n",
    "        exp_df['EduExp{}_{}'.format(str(e),ghusername)].astype(object)\n",
    "    \n",
    "    # Get the index to locate each relevant bit of information\n",
    "    ts_index = exp_df.index\n",
    "    \n",
    "    \n",
    "    # Jobs -----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Populate the new columns with the relevant experience\n",
    "    for j in range(num_jobs):\n",
    "        for date in ts_index:\n",
    "            # Create the relevant cells if the date index is within the beginning and start dates\n",
    "            if (jobs_list[j][0]['dates'][0] <= date) & (jobs_list[j][0]['dates'][1] >= date):\n",
    "                exp_df.set_value(date,'JobExp{}_{}'.format(str(j),ghusername),jobs_list[j][0])\n",
    "    \n",
    "    # Education -----------------------------------------------------------------------------------------------   \n",
    "    \n",
    "    # Populate the new columns with the relevant experience\n",
    "    for j in range(num_edu):\n",
    "        for date in ts_index:\n",
    "            # Create the relevant cells if the date index is within the beginning and start dates\n",
    "            if (edu_list[j][0]['dates'][0] <= date) and (edu_list[j][0]['dates'][1] >= date):\n",
    "                exp_df.set_value(date,'EduExp{}_{}'.format(str(j),ghusername), edu_list[j][0])\n",
    "                \n",
    "\n",
    "    return exp_df\n",
    "    \n",
    "# --------------------------------------------------\n",
    "\n",
    "user_allexp = [get_numexp(user_allexp[i],main_df,i) for i in range(len(main_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T18:09:23.622226",
     "start_time": "2016-12-13T17:23:14.816500"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "my bar!: 61it [00:04, 14.31it/s]\n",
      "my bar!: 58it [00:04, 14.18it/s]\n",
      "my bar!: 54it [00:03, 13.71it/s]\n",
      "my bar!: 48it [00:03, 14.81it/s]\n",
      "my bar!: 53it [00:03, 15.05it/s]\n",
      "my bar!: 58it [00:04, 13.97it/s]\n",
      "my bar!: 53it [00:03, 13.67it/s]\n",
      "my bar!: 48it [00:03, 14.98it/s]\n",
      "my bar!: 58it [00:03, 15.61it/s]\n",
      "my bar!: 57it [00:03, 14.54it/s]\n",
      "my bar!: 52it [00:03, 14.14it/s]\n",
      "my bar!: 48it [00:03, 14.36it/s]\n",
      "my bar!: 51it [00:03, 15.18it/s]\n",
      "my bar!: 56it [00:03, 14.47it/s]\n",
      "my bar!: 55it [00:04, 11.93it/s]\n",
      "my bar!: 52it [00:03, 13.36it/s]\n",
      "my bar!: 48it [00:03, 13.50it/s]\n",
      "my bar!: 53it [00:03, 14.07it/s]\n",
      "my bar!: 57it [00:03, 15.98it/s]\n",
      "my bar!: 53it [00:03, 15.76it/s]\n",
      "my bar!: 48it [00:03, 15.91it/s]\n",
      "my bar!: 48it [00:03, 14.24it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 55it [00:03, 15.63it/s]\n",
      "my bar!: 55it [00:03, 15.92it/s]\n",
      "my bar!: 48it [00:03, 15.86it/s]\n",
      "my bar!: 59it [00:03, 15.37it/s]\n",
      "my bar!: 48it [00:03, 15.76it/s]\n",
      "my bar!: 51it [00:03, 12.95it/s]\n",
      "my bar!: 55it [00:03, 14.21it/s]\n",
      "my bar!: 50it [00:03, 15.59it/s]\n",
      "my bar!: 51it [00:03, 15.23it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 48it [00:03, 15.60it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 53it [00:03, 15.18it/s]\n",
      "my bar!: 48it [00:03, 15.85it/s]\n",
      "my bar!: 54it [00:03, 15.51it/s]\n",
      "my bar!: 60it [00:03, 15.13it/s]\n",
      "my bar!: 51it [00:03, 14.54it/s]\n",
      "my bar!: 48it [00:03, 15.10it/s]\n",
      "my bar!: 48it [00:03, 15.25it/s]\n",
      "my bar!: 48it [00:03, 15.60it/s]\n",
      "my bar!: 54it [00:03, 14.89it/s]\n",
      "my bar!: 55it [00:03, 15.64it/s]\n",
      "my bar!: 51it [00:03, 13.68it/s]\n",
      "my bar!: 49it [00:03, 14.69it/s]\n",
      "my bar!: 52it [00:03, 13.83it/s]\n",
      "my bar!: 48it [00:03, 15.39it/s]\n",
      "my bar!: 48it [00:03, 14.97it/s]\n",
      "my bar!: 48it [00:03, 14.47it/s]\n",
      "my bar!: 52it [00:03, 13.70it/s]\n",
      "my bar!: 52it [00:03, 15.19it/s]\n",
      "my bar!: 48it [00:03, 15.12it/s]\n",
      "my bar!: 54it [00:03, 15.57it/s]\n",
      "my bar!: 59it [00:03, 16.00it/s]\n",
      "my bar!: 52it [00:03, 15.78it/s]\n",
      "my bar!: 59it [00:03, 14.70it/s]\n",
      "my bar!: 48it [00:03, 14.93it/s]\n",
      "my bar!: 56it [00:03, 15.92it/s]\n",
      "my bar!: 48it [00:03, 15.94it/s]\n",
      "my bar!: 48it [00:03, 15.39it/s]\n",
      "my bar!: 52it [00:03, 14.98it/s]\n",
      "my bar!: 48it [00:03, 15.21it/s]\n",
      "my bar!: 54it [00:03, 15.65it/s]\n",
      "my bar!: 48it [00:03, 15.64it/s]\n",
      "my bar!: 50it [00:03, 14.44it/s]\n",
      "my bar!: 54it [00:03, 15.18it/s]\n",
      "my bar!: 54it [00:03, 15.33it/s]\n",
      "my bar!: 56it [00:03, 14.90it/s]\n",
      "my bar!: 48it [00:03, 14.96it/s]\n",
      "my bar!: 48it [00:03, 15.54it/s]\n",
      "my bar!: 52it [00:03, 15.85it/s]\n",
      "my bar!: 48it [00:03, 15.81it/s]\n",
      "my bar!: 60it [00:04, 13.79it/s]\n",
      "my bar!: 55it [00:03, 14.48it/s]\n",
      "my bar!: 48it [00:03, 15.50it/s]\n",
      "my bar!: 58it [00:03, 16.03it/s]\n",
      "my bar!: 48it [00:03, 14.62it/s]\n",
      "my bar!: 58it [00:03, 15.06it/s]\n",
      "my bar!: 50it [00:03, 15.98it/s]\n",
      "my bar!: 48it [00:03, 15.71it/s]\n",
      "my bar!: 48it [00:03, 15.54it/s]\n",
      "my bar!: 48it [00:03, 15.82it/s]\n",
      "my bar!: 48it [00:03, 15.02it/s]\n",
      "my bar!: 48it [00:03, 14.33it/s]\n",
      "my bar!: 48it [00:03, 14.76it/s]\n",
      "my bar!: 48it [00:03, 15.60it/s]\n",
      "my bar!: 53it [00:03, 15.83it/s]\n",
      "my bar!: 56it [00:03, 14.77it/s]\n",
      "my bar!: 48it [00:03, 14.23it/s]\n",
      "my bar!: 48it [00:03, 13.85it/s]\n",
      "my bar!: 50it [00:03, 15.04it/s]\n",
      "my bar!: 48it [00:03, 15.48it/s]\n",
      "my bar!: 51it [00:03, 15.96it/s]\n",
      "my bar!: 53it [00:03, 15.50it/s]\n",
      "my bar!: 53it [00:03, 15.55it/s]\n",
      "my bar!: 50it [00:03, 15.51it/s]\n",
      "my bar!: 59it [00:03, 15.69it/s]\n",
      "my bar!: 48it [00:03, 15.54it/s]\n",
      "my bar!: 48it [00:03, 15.64it/s]\n",
      "my bar!: 48it [00:03, 15.02it/s]\n",
      "my bar!: 51it [00:03, 15.57it/s]\n",
      "my bar!: 52it [00:03, 15.61it/s]\n",
      "my bar!: 48it [00:03, 15.48it/s]\n",
      "my bar!: 55it [00:03, 16.09it/s]\n",
      "my bar!: 49it [00:03, 15.91it/s]\n",
      "my bar!: 52it [00:03, 15.40it/s]\n",
      "my bar!: 54it [00:03, 14.98it/s]\n",
      "my bar!: 55it [00:03, 15.23it/s]\n",
      "my bar!: 48it [00:03, 15.08it/s]\n",
      "my bar!: 48it [00:03, 14.85it/s]\n",
      "my bar!: 54it [00:03, 15.80it/s]\n",
      "my bar!: 50it [00:03, 14.34it/s]\n",
      "my bar!: 52it [00:03, 14.01it/s]\n",
      "my bar!: 48it [00:03, 15.54it/s]\n",
      "my bar!: 48it [00:03, 14.35it/s]\n",
      "my bar!: 55it [00:03, 14.70it/s]\n",
      "my bar!: 54it [00:03, 15.43it/s]\n",
      "my bar!: 54it [00:03, 15.07it/s]\n",
      "my bar!: 48it [00:03, 14.82it/s]\n",
      "my bar!: 50it [00:03, 14.49it/s]\n",
      "my bar!: 51it [00:03, 16.55it/s]\n",
      "my bar!: 48it [00:03, 15.39it/s]\n",
      "my bar!: 53it [00:03, 15.55it/s]\n",
      "my bar!: 53it [00:03, 15.48it/s]\n",
      "my bar!: 57it [00:03, 15.73it/s]\n",
      "my bar!: 50it [00:03, 15.56it/s]\n",
      "my bar!: 61it [00:03, 15.85it/s]\n",
      "my bar!: 48it [00:03, 15.40it/s]\n",
      "my bar!: 54it [00:03, 15.26it/s]\n",
      "my bar!: 50it [00:03, 15.51it/s]\n",
      "my bar!: 52it [00:03, 15.29it/s]\n",
      "my bar!: 48it [00:03, 15.56it/s]\n",
      "my bar!: 54it [00:03, 15.96it/s]\n",
      "my bar!: 48it [00:03, 15.06it/s]\n",
      "my bar!: 48it [00:03, 15.91it/s]\n",
      "my bar!: 48it [00:03, 15.85it/s]\n",
      "my bar!: 51it [00:03, 15.42it/s]\n",
      "my bar!: 53it [00:03, 16.25it/s]\n",
      "my bar!: 54it [00:03, 15.07it/s]\n",
      "my bar!: 56it [00:03, 15.05it/s]\n",
      "my bar!: 48it [00:03, 14.62it/s]\n",
      "my bar!: 56it [00:03, 15.58it/s]\n",
      "my bar!: 48it [00:03, 15.43it/s]\n",
      "my bar!: 48it [00:03, 15.29it/s]\n",
      "my bar!: 56it [00:03, 15.51it/s]\n",
      "my bar!: 49it [00:03, 15.67it/s]\n",
      "my bar!: 54it [00:03, 15.56it/s]\n",
      "my bar!: 48it [00:03, 15.84it/s]\n",
      "my bar!: 54it [00:03, 14.90it/s]\n",
      "my bar!: 48it [00:03, 14.51it/s]\n",
      "my bar!: 48it [00:03, 14.27it/s]\n",
      "my bar!: 48it [00:03, 14.36it/s]\n",
      "my bar!: 62it [00:04, 14.20it/s]\n",
      "my bar!: 53it [00:03, 14.58it/s]\n",
      "my bar!: 48it [00:03, 14.19it/s]\n",
      "my bar!: 48it [00:03, 14.48it/s]\n",
      "my bar!: 48it [00:03, 14.26it/s]\n",
      "my bar!: 48it [00:03, 14.42it/s]\n",
      "my bar!: 48it [00:03, 14.50it/s]\n",
      "my bar!: 52it [00:03, 14.43it/s]\n",
      "my bar!: 48it [00:03, 14.53it/s]\n",
      "my bar!: 48it [00:03, 15.00it/s]\n",
      "my bar!: 51it [00:03, 14.03it/s]\n",
      "my bar!: 55it [00:03, 14.24it/s]\n",
      "my bar!: 59it [00:03, 14.53it/s]\n",
      "my bar!: 59it [00:04, 14.42it/s]\n",
      "my bar!: 55it [00:03, 13.67it/s]\n",
      "my bar!: 48it [00:03, 13.99it/s]\n",
      "my bar!: 54it [00:03, 14.43it/s]\n",
      "my bar!: 52it [00:03, 14.85it/s]\n",
      "my bar!: 48it [00:03, 14.57it/s]\n",
      "my bar!: 48it [00:03, 14.52it/s]\n",
      "my bar!: 52it [00:03, 14.52it/s]\n",
      "my bar!: 58it [00:04, 14.42it/s]\n",
      "my bar!: 48it [00:03, 15.20it/s]\n",
      "my bar!: 50it [00:03, 15.15it/s]\n",
      "my bar!: 48it [00:03, 14.09it/s]\n",
      "my bar!: 48it [00:03, 14.49it/s]\n",
      "my bar!: 52it [00:03, 15.55it/s]\n",
      "my bar!: 48it [00:03, 15.68it/s]\n",
      "my bar!: 48it [00:03, 14.49it/s]\n",
      "my bar!: 48it [00:03, 14.89it/s]\n",
      "my bar!: 58it [00:03, 14.98it/s]\n",
      "my bar!: 48it [00:03, 15.57it/s]\n",
      "my bar!: 58it [00:03, 14.73it/s]\n",
      "my bar!: 61it [00:03, 16.07it/s]\n",
      "my bar!: 52it [00:03, 14.92it/s]\n",
      "my bar!: 55it [00:03, 16.02it/s]\n",
      "my bar!: 50it [00:03, 14.66it/s]\n",
      "my bar!: 50it [00:03, 15.01it/s]\n",
      "my bar!: 48it [00:03, 15.17it/s]\n",
      "my bar!: 48it [00:03, 14.92it/s]\n",
      "my bar!: 48it [00:03, 14.36it/s]\n",
      "my bar!: 48it [00:03, 14.30it/s]\n",
      "my bar!: 48it [00:03, 14.16it/s]\n",
      "my bar!: 50it [00:03, 14.73it/s]\n",
      "my bar!: 50it [00:03, 14.42it/s]\n",
      "my bar!: 59it [00:03, 14.60it/s]\n",
      "my bar!: 51it [00:03, 14.09it/s]\n",
      "my bar!: 48it [00:03, 14.52it/s]\n",
      "my bar!: 52it [00:03, 14.62it/s]\n",
      "my bar!: 54it [00:03, 15.46it/s]\n",
      "my bar!: 50it [00:03, 15.56it/s]\n",
      "my bar!: 48it [00:03, 15.63it/s]\n",
      "my bar!: 55it [00:03, 14.61it/s]\n",
      "my bar!: 59it [00:03, 15.79it/s]\n",
      "my bar!: 48it [00:03, 14.75it/s]\n",
      "my bar!: 59it [00:03, 15.74it/s]\n",
      "my bar!: 56it [00:03, 15.58it/s]\n",
      "my bar!: 53it [00:03, 15.46it/s]\n",
      "my bar!: 50it [00:03, 15.97it/s]\n",
      "my bar!: 48it [00:03, 15.01it/s]\n",
      "my bar!: 48it [00:03, 15.19it/s]\n",
      "my bar!: 48it [00:03, 14.94it/s]\n",
      "my bar!: 63it [00:04, 14.76it/s]\n",
      "my bar!: 48it [00:03, 15.86it/s]\n",
      "my bar!: 52it [00:03, 15.80it/s]\n",
      "my bar!: 48it [00:02, 16.05it/s]\n",
      "my bar!: 48it [00:03, 15.83it/s]\n",
      "my bar!: 48it [00:03, 15.47it/s]\n",
      "my bar!: 52it [00:03, 14.81it/s]\n",
      "my bar!: 59it [00:03, 14.62it/s]\n",
      "my bar!: 56it [00:03, 15.24it/s]\n",
      "my bar!: 58it [00:03, 15.86it/s]\n",
      "my bar!: 48it [00:03, 15.79it/s]\n",
      "my bar!: 52it [00:03, 15.89it/s]\n",
      "my bar!: 48it [00:03, 15.79it/s]\n",
      "my bar!: 60it [00:03, 15.88it/s]\n",
      "my bar!: 48it [00:02, 16.13it/s]\n",
      "my bar!: 52it [00:03, 15.80it/s]\n",
      "my bar!: 58it [00:03, 15.91it/s]\n",
      "my bar!: 48it [00:03, 15.69it/s]\n",
      "my bar!: 53it [00:03, 16.13it/s]\n",
      "my bar!: 50it [00:03, 15.90it/s]\n",
      "my bar!: 50it [00:03, 15.43it/s]\n",
      "my bar!: 48it [00:03, 15.34it/s]\n",
      "my bar!: 48it [00:03, 15.70it/s]\n",
      "my bar!: 48it [00:03, 14.99it/s]\n",
      "my bar!: 50it [00:03, 14.34it/s]\n",
      "my bar!: 52it [00:03, 14.33it/s]\n",
      "my bar!: 48it [00:03, 15.79it/s]\n",
      "my bar!: 57it [00:03, 15.89it/s]\n",
      "my bar!: 48it [00:03, 15.26it/s]\n",
      "my bar!: 56it [00:03, 15.06it/s]\n",
      "my bar!: 53it [00:03, 15.79it/s]\n",
      "my bar!: 48it [00:03, 15.88it/s]\n",
      "my bar!: 60it [00:03, 16.06it/s]\n",
      "my bar!: 52it [00:03, 15.80it/s]\n",
      "my bar!: 54it [00:03, 15.59it/s]\n",
      "my bar!: 58it [00:03, 14.77it/s]\n",
      "my bar!: 55it [00:03, 15.08it/s]\n",
      "my bar!: 54it [00:03, 14.75it/s]\n",
      "my bar!: 51it [00:03, 14.92it/s]\n",
      "my bar!: 56it [00:03, 14.96it/s]\n",
      "my bar!: 48it [00:03, 15.41it/s]\n",
      "my bar!: 52it [00:03, 14.73it/s]\n",
      "my bar!: 52it [00:03, 14.52it/s]\n",
      "my bar!: 48it [00:03, 14.69it/s]\n",
      "my bar!: 54it [00:03, 15.45it/s]\n",
      "my bar!: 48it [00:03, 15.60it/s]\n",
      "my bar!: 48it [00:03, 14.27it/s]\n",
      "my bar!: 52it [00:03, 14.67it/s]\n",
      "my bar!: 49it [00:03, 16.22it/s]\n",
      "my bar!: 49it [00:03, 15.96it/s]\n",
      "my bar!: 55it [00:03, 15.36it/s]\n",
      "my bar!: 58it [00:03, 14.75it/s]\n",
      "my bar!: 48it [00:03, 15.16it/s]\n",
      "my bar!: 48it [00:03, 15.42it/s]\n",
      "my bar!: 56it [00:03, 15.53it/s]\n",
      "my bar!: 48it [00:03, 15.40it/s]\n",
      "my bar!: 52it [00:03, 14.78it/s]\n",
      "my bar!: 48it [00:03, 14.45it/s]\n",
      "my bar!: 48it [00:03, 14.74it/s]\n",
      "my bar!: 59it [00:04, 14.28it/s]\n",
      "my bar!: 48it [00:03, 15.33it/s]\n",
      "my bar!: 55it [00:03, 14.97it/s]\n",
      "my bar!: 52it [00:03, 15.43it/s]\n",
      "my bar!: 48it [00:03, 14.39it/s]\n",
      "my bar!: 48it [00:03, 13.91it/s]\n",
      "my bar!: 53it [00:03, 13.98it/s]\n",
      "my bar!: 60it [00:04, 13.75it/s]\n",
      "my bar!: 50it [00:03, 13.47it/s]\n",
      "my bar!: 51it [00:03, 14.00it/s]\n",
      "my bar!: 48it [00:03, 14.49it/s]\n",
      "my bar!: 48it [00:03, 14.15it/s]\n",
      "my bar!: 48it [00:03, 14.76it/s]\n",
      "my bar!: 48it [00:03, 12.04it/s]\n",
      "my bar!: 48it [00:03, 12.39it/s]\n",
      "my bar!: 48it [00:05,  7.92it/s]\n",
      "my bar!: 48it [00:04, 13.12it/s]\n",
      "my bar!: 48it [00:03, 13.12it/s]\n",
      "my bar!: 51it [00:03, 14.29it/s]\n",
      "my bar!: 48it [00:03, 15.28it/s]\n",
      "my bar!: 54it [00:03, 14.16it/s]\n",
      "my bar!: 64it [00:04, 14.43it/s]\n",
      "my bar!: 48it [00:03, 14.04it/s]\n",
      "my bar!: 48it [00:03, 14.31it/s]\n",
      "my bar!: 60it [00:04, 14.35it/s]\n",
      "my bar!: 50it [00:03, 14.19it/s]\n",
      "my bar!: 48it [00:03, 14.13it/s]\n",
      "my bar!: 54it [00:03, 13.95it/s]\n",
      "my bar!: 53it [00:03, 14.31it/s]\n",
      "my bar!: 48it [00:03, 14.42it/s]\n",
      "my bar!: 58it [00:04, 14.29it/s]\n",
      "my bar!: 54it [00:03, 14.18it/s]\n",
      "my bar!: 58it [00:04, 14.22it/s]\n",
      "my bar!: 48it [00:03, 14.95it/s]\n",
      "my bar!: 48it [00:03, 14.68it/s]\n",
      "my bar!: 48it [00:03, 14.03it/s]\n",
      "my bar!: 48it [00:03, 14.67it/s]\n",
      "my bar!: 48it [00:03, 14.47it/s]\n",
      "my bar!: 48it [00:03, 15.03it/s]\n",
      "my bar!: 48it [00:03, 15.98it/s]\n",
      "my bar!: 48it [00:03, 15.21it/s]\n",
      "my bar!: 51it [00:03, 15.51it/s]\n",
      "my bar!: 52it [00:03, 15.93it/s]\n",
      "my bar!: 52it [00:03, 15.91it/s]\n",
      "my bar!: 48it [00:03, 15.89it/s]\n",
      "my bar!: 48it [00:03, 15.89it/s]\n",
      "my bar!: 52it [00:03, 15.59it/s]\n",
      "my bar!: 48it [00:03, 15.85it/s]\n",
      "my bar!: 48it [00:02, 16.02it/s]\n",
      "my bar!: 48it [00:03, 15.23it/s]\n",
      "my bar!: 51it [00:03, 14.63it/s]\n",
      "my bar!: 53it [00:03, 13.92it/s]\n",
      "my bar!: 57it [00:03, 14.75it/s]\n",
      "my bar!: 48it [00:03, 14.81it/s]\n",
      "my bar!: 48it [00:03, 14.54it/s]\n",
      "my bar!: 54it [00:03, 14.04it/s]\n",
      "my bar!: 48it [00:03, 14.86it/s]\n",
      "my bar!: 52it [00:03, 15.44it/s]\n",
      "my bar!: 52it [00:03, 15.31it/s]\n",
      "my bar!: 48it [00:03, 15.11it/s]\n",
      "my bar!: 52it [00:03, 15.50it/s]\n",
      "my bar!: 54it [00:03, 15.69it/s]\n",
      "my bar!: 48it [00:03, 15.83it/s]\n",
      "my bar!: 48it [00:03, 15.30it/s]\n",
      "my bar!: 48it [00:03, 14.61it/s]\n",
      "my bar!: 56it [00:03, 15.85it/s]\n",
      "my bar!: 48it [00:03, 15.41it/s]\n",
      "my bar!: 48it [00:03, 13.38it/s]\n",
      "my bar!: 48it [00:03, 14.42it/s]\n",
      "my bar!: 55it [00:03, 13.12it/s]\n",
      "my bar!: 52it [00:03, 14.62it/s]\n",
      "my bar!: 51it [00:03, 14.80it/s]\n",
      "my bar!: 48it [00:03, 14.60it/s]\n",
      "my bar!: 53it [00:03, 16.39it/s]\n",
      "my bar!: 48it [00:03, 15.87it/s]\n",
      "my bar!: 48it [00:02, 16.09it/s]\n",
      "my bar!: 51it [00:03, 15.52it/s]\n",
      "my bar!: 48it [00:03, 14.59it/s]\n",
      "my bar!: 52it [00:03, 14.45it/s]\n",
      "my bar!: 48it [00:03, 15.22it/s]\n",
      "my bar!: 48it [00:03, 14.65it/s]\n",
      "my bar!: 51it [00:03, 15.22it/s]\n",
      "my bar!: 55it [00:03, 14.38it/s]\n",
      "my bar!: 48it [00:03, 14.84it/s]\n",
      "my bar!: 48it [00:03, 15.04it/s]\n",
      "my bar!: 48it [00:03, 15.80it/s]\n",
      "my bar!: 59it [00:03, 14.71it/s]\n",
      "my bar!: 48it [00:03, 14.78it/s]\n",
      "my bar!: 48it [00:03, 14.35it/s]\n",
      "my bar!: 50it [00:03, 15.20it/s]\n",
      "my bar!: 50it [00:03, 15.48it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 50it [00:03, 15.75it/s]\n",
      "my bar!: 48it [00:03, 15.07it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 50it [00:03, 15.60it/s]\n",
      "my bar!: 54it [00:03, 15.70it/s]\n",
      "my bar!: 48it [00:03, 15.98it/s]\n",
      "my bar!: 53it [00:03, 16.00it/s]\n",
      "my bar!: 50it [00:03, 15.70it/s]\n",
      "my bar!: 48it [00:03, 15.47it/s]\n",
      "my bar!: 51it [00:03, 15.48it/s]\n",
      "my bar!: 48it [00:03, 15.01it/s]\n",
      "my bar!: 52it [00:03, 14.52it/s]\n",
      "my bar!: 50it [00:03, 14.48it/s]\n",
      "my bar!: 56it [00:03, 14.25it/s]\n",
      "my bar!: 50it [00:03, 13.88it/s]\n",
      "my bar!: 51it [00:03, 14.33it/s]\n",
      "my bar!: 48it [00:03, 14.49it/s]\n",
      "my bar!: 48it [00:03, 14.42it/s]\n",
      "my bar!: 49it [00:03, 15.38it/s]\n",
      "my bar!: 48it [00:03, 14.58it/s]\n",
      "my bar!: 56it [00:03, 14.46it/s]\n",
      "my bar!: 48it [00:03, 14.54it/s]\n",
      "my bar!: 48it [00:03, 14.78it/s]\n",
      "my bar!: 56it [00:03, 14.43it/s]\n",
      "my bar!: 51it [00:03, 16.34it/s]\n",
      "my bar!: 48it [00:03, 15.60it/s]\n",
      "my bar!: 56it [00:03, 15.60it/s]\n",
      "my bar!: 56it [00:03, 15.69it/s]\n",
      "my bar!: 49it [00:03, 15.85it/s]\n",
      "my bar!: 61it [00:03, 14.96it/s]\n",
      "my bar!: 53it [00:03, 14.85it/s]\n",
      "my bar!: 48it [00:03, 14.92it/s]\n",
      "my bar!: 50it [00:03, 14.63it/s]\n",
      "my bar!: 56it [00:03, 14.50it/s]\n",
      "my bar!: 48it [00:03, 14.94it/s]\n",
      "my bar!: 55it [00:03, 15.46it/s]\n",
      "my bar!: 48it [00:03, 15.32it/s]\n",
      "my bar!: 51it [00:03, 15.53it/s]\n",
      "my bar!: 57it [00:03, 14.16it/s]\n",
      "my bar!: 53it [00:03, 15.61it/s]\n",
      "my bar!: 52it [00:03, 15.17it/s]\n",
      "my bar!: 52it [00:03, 15.21it/s]\n",
      "my bar!: 48it [00:03, 15.51it/s]\n",
      "my bar!: 48it [00:03, 13.89it/s]\n",
      "my bar!: 51it [00:03, 15.35it/s]\n",
      "my bar!: 58it [00:03, 15.20it/s]\n",
      "my bar!: 56it [00:03, 15.60it/s]\n",
      "my bar!: 50it [00:03, 15.81it/s]\n",
      "my bar!: 48it [00:02, 16.00it/s]\n",
      "my bar!: 50it [00:03, 15.64it/s]\n",
      "my bar!: 48it [00:03, 15.70it/s]\n",
      "my bar!: 53it [00:03, 15.81it/s]\n",
      "my bar!: 51it [00:03, 15.47it/s]\n",
      "my bar!: 54it [00:03, 14.88it/s]\n",
      "my bar!: 48it [00:03, 14.29it/s]\n",
      "my bar!: 48it [00:03, 14.83it/s]\n",
      "my bar!: 54it [00:03, 14.60it/s]\n",
      "my bar!: 48it [00:03, 14.63it/s]\n",
      "my bar!: 52it [00:03, 14.52it/s]\n",
      "my bar!: 53it [00:03, 15.83it/s]\n",
      "my bar!: 48it [00:03, 15.31it/s]\n",
      "my bar!: 59it [00:03, 14.04it/s]\n",
      "my bar!: 48it [00:03, 14.79it/s]\n",
      "my bar!: 48it [00:03, 15.93it/s]\n",
      "my bar!: 50it [00:03, 15.07it/s]\n",
      "my bar!: 48it [00:03, 15.16it/s]\n",
      "my bar!: 64it [00:04, 15.62it/s]\n",
      "my bar!: 48it [00:03, 15.25it/s]\n",
      "my bar!: 50it [00:03, 15.49it/s]\n",
      "my bar!: 48it [00:03, 15.70it/s]\n",
      "my bar!: 56it [00:03, 15.00it/s]\n",
      "my bar!: 53it [00:03, 14.40it/s]\n",
      "my bar!: 48it [00:03, 14.81it/s]\n",
      "my bar!: 55it [00:03, 15.79it/s]\n",
      "my bar!: 55it [00:03, 13.52it/s]\n",
      "my bar!: 62it [00:04, 14.75it/s]\n",
      "my bar!: 54it [00:03, 15.65it/s]\n",
      "my bar!: 56it [00:03, 15.84it/s]\n",
      "my bar!: 49it [00:02, 16.51it/s]\n",
      "my bar!: 52it [00:03, 15.84it/s]\n",
      "my bar!: 48it [00:03, 15.87it/s]\n",
      "my bar!: 48it [00:03, 15.90it/s]\n",
      "my bar!: 55it [00:03, 15.94it/s]\n",
      "my bar!: 54it [00:03, 16.10it/s]\n",
      "my bar!: 48it [00:03, 15.95it/s]\n",
      "my bar!: 51it [00:03, 15.99it/s]\n",
      "my bar!: 54it [00:03, 15.92it/s]\n",
      "my bar!: 48it [00:03, 15.35it/s]\n",
      "my bar!: 51it [00:03, 16.06it/s]\n",
      "my bar!: 56it [00:03, 15.74it/s]\n",
      "my bar!: 48it [00:03, 15.94it/s]\n",
      "my bar!: 48it [00:03, 15.86it/s]\n",
      "my bar!: 48it [00:03, 15.19it/s]\n",
      "my bar!: 56it [00:03, 15.38it/s]\n",
      "my bar!: 53it [00:03, 16.04it/s]\n",
      "my bar!: 51it [00:03, 14.66it/s]\n",
      "my bar!: 49it [00:03, 15.74it/s]\n",
      "my bar!: 48it [00:03, 15.94it/s]\n",
      "my bar!: 48it [00:03, 15.95it/s]\n",
      "my bar!: 54it [00:03, 15.53it/s]\n",
      "my bar!: 52it [00:03, 14.88it/s]\n",
      "my bar!: 48it [00:03, 14.84it/s]\n",
      "my bar!: 53it [00:03, 14.60it/s]\n",
      "my bar!: 53it [00:03, 15.41it/s]\n",
      "my bar!: 49it [00:03, 16.03it/s]\n",
      "my bar!: 48it [00:03, 15.14it/s]\n",
      "my bar!: 54it [00:03, 14.51it/s]\n",
      "my bar!: 50it [00:03, 15.96it/s]\n",
      "my bar!: 54it [00:03, 15.36it/s]\n",
      "my bar!: 48it [00:03, 15.50it/s]\n",
      "my bar!: 50it [00:03, 15.24it/s]\n",
      "my bar!: 53it [00:03, 14.99it/s]\n",
      "my bar!: 51it [00:03, 14.53it/s]\n",
      "my bar!: 48it [00:03, 15.05it/s]\n",
      "my bar!: 51it [00:03, 15.76it/s]\n",
      "my bar!: 48it [00:03, 15.14it/s]\n",
      "my bar!: 50it [00:03, 14.79it/s]\n",
      "my bar!: 48it [00:03, 14.74it/s]\n",
      "my bar!: 48it [00:03, 15.25it/s]\n",
      "my bar!: 58it [00:03, 15.31it/s]\n",
      "my bar!: 55it [00:03, 14.41it/s]\n",
      "my bar!: 48it [00:03, 15.00it/s]\n",
      "my bar!: 48it [00:03, 15.85it/s]\n",
      "my bar!: 48it [00:03, 14.90it/s]\n",
      "my bar!: 56it [00:03, 15.12it/s]\n",
      "my bar!: 54it [00:03, 15.62it/s]\n",
      "my bar!: 48it [00:03, 14.59it/s]\n",
      "my bar!: 52it [00:03, 14.61it/s]\n",
      "my bar!: 59it [00:03, 15.63it/s]\n",
      "my bar!: 57it [00:03, 14.56it/s]\n",
      "my bar!: 52it [00:03, 14.42it/s]\n",
      "my bar!: 55it [00:03, 15.43it/s]\n",
      "my bar!: 51it [00:03, 15.72it/s]\n",
      "my bar!: 49it [00:03, 15.97it/s]\n",
      "my bar!: 52it [00:03, 15.70it/s]\n",
      "my bar!: 48it [00:03, 15.74it/s]\n",
      "my bar!: 56it [00:03, 15.48it/s]\n",
      "my bar!: 48it [00:03, 15.52it/s]\n",
      "my bar!: 54it [00:03, 15.42it/s]\n",
      "my bar!: 54it [00:03, 15.36it/s]\n",
      "my bar!: 48it [00:03, 15.46it/s]\n",
      "my bar!: 55it [00:03, 15.72it/s]\n",
      "my bar!: 48it [00:03, 15.62it/s]\n",
      "my bar!: 48it [00:03, 15.59it/s]\n",
      "my bar!: 48it [00:03, 15.93it/s]\n",
      "my bar!: 61it [00:03, 15.82it/s]\n",
      "my bar!: 48it [00:03, 15.73it/s]\n",
      "my bar!: 57it [00:03, 15.70it/s]\n",
      "my bar!: 62it [00:04, 15.39it/s]\n",
      "my bar!: 52it [00:03, 15.54it/s]\n",
      "my bar!: 54it [00:03, 15.58it/s]\n",
      "my bar!: 51it [00:03, 16.24it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 54it [00:03, 14.88it/s]\n",
      "my bar!: 48it [00:03, 15.23it/s]\n",
      "my bar!: 48it [00:03, 14.46it/s]\n",
      "my bar!: 51it [00:03, 15.53it/s]\n",
      "my bar!: 48it [00:03, 15.68it/s]\n",
      "my bar!: 48it [00:03, 15.62it/s]\n",
      "my bar!: 48it [00:03, 15.64it/s]\n",
      "my bar!: 48it [00:03, 15.97it/s]\n",
      "my bar!: 51it [00:03, 15.55it/s]\n",
      "my bar!: 48it [00:03, 14.89it/s]\n",
      "my bar!: 54it [00:03, 14.58it/s]\n",
      "my bar!: 48it [00:03, 14.01it/s]\n",
      "my bar!: 53it [00:03, 13.85it/s]\n",
      "my bar!: 59it [00:03, 15.46it/s]\n",
      "my bar!: 56it [00:03, 15.24it/s]\n",
      "my bar!: 48it [00:03, 14.70it/s]\n",
      "my bar!: 53it [00:03, 14.70it/s]\n",
      "my bar!: 54it [00:04, 13.26it/s]\n",
      "my bar!: 53it [00:03, 15.33it/s]\n",
      "my bar!: 48it [00:03, 14.59it/s]\n",
      "my bar!: 50it [00:03, 14.20it/s]\n",
      "my bar!: 49it [00:03, 14.56it/s]\n",
      "my bar!: 48it [00:03, 14.52it/s]\n",
      "my bar!: 51it [00:03, 15.63it/s]\n",
      "my bar!: 48it [00:03, 14.89it/s]\n",
      "my bar!: 48it [00:03, 14.44it/s]\n",
      "my bar!: 48it [00:03, 14.52it/s]\n",
      "my bar!: 48it [00:03, 14.86it/s]\n",
      "my bar!: 48it [00:03, 13.92it/s]\n",
      "my bar!: 51it [00:03, 14.23it/s]\n",
      "my bar!: 48it [00:03, 14.47it/s]\n",
      "my bar!: 48it [00:03, 15.35it/s]\n",
      "my bar!: 48it [00:03, 14.71it/s]\n",
      "my bar!: 55it [00:03, 15.55it/s]\n",
      "my bar!: 50it [00:03, 15.57it/s]\n",
      "my bar!: 48it [00:03, 15.61it/s]\n",
      "my bar!: 48it [00:03, 15.79it/s]\n",
      "my bar!: 48it [00:03, 14.94it/s]\n",
      "my bar!: 51it [00:03, 14.52it/s]\n",
      "my bar!: 48it [00:03, 13.46it/s]\n",
      "my bar!: 48it [00:03, 13.17it/s]\n",
      "my bar!: 50it [00:03, 12.85it/s]\n",
      "my bar!: 48it [00:04, 13.74it/s]\n",
      "my bar!: 54it [00:04, 13.51it/s]\n",
      "my bar!: 48it [00:03, 15.14it/s]\n",
      "my bar!: 48it [00:03, 15.27it/s]\n",
      "my bar!: 48it [00:03, 15.41it/s]\n",
      "my bar!: 48it [00:03, 15.53it/s]\n",
      "my bar!: 54it [00:03, 15.29it/s]\n",
      "my bar!: 48it [00:03, 15.55it/s]\n",
      "my bar!: 50it [00:03, 15.48it/s]\n",
      "my bar!: 48it [00:03, 15.45it/s]\n",
      "my bar!: 50it [00:03, 15.35it/s]\n",
      "my bar!: 56it [00:03, 15.57it/s]\n",
      "my bar!: 58it [00:03, 15.51it/s]\n",
      "my bar!: 56it [00:03, 15.21it/s]\n",
      "my bar!: 48it [00:03, 15.31it/s]\n",
      "my bar!: 59it [00:03, 14.74it/s]\n",
      "my bar!: 52it [00:03, 15.41it/s]\n",
      "my bar!: 57it [00:03, 15.14it/s]\n",
      "my bar!: 48it [00:03, 15.33it/s]\n",
      "my bar!: 55it [00:03, 15.49it/s]\n",
      "my bar!: 59it [00:03, 15.60it/s]\n",
      "my bar!: 48it [00:03, 15.42it/s]\n",
      "my bar!: 48it [00:03, 15.40it/s]\n",
      "my bar!: 48it [00:03, 15.60it/s]\n",
      "my bar!: 60it [00:03, 15.44it/s]\n",
      "my bar!: 49it [00:03, 15.58it/s]\n",
      "my bar!: 48it [00:03, 15.47it/s]\n",
      "my bar!: 48it [00:03, 15.59it/s]\n",
      "my bar!: 48it [00:03, 15.46it/s]\n",
      "my bar!: 48it [00:03, 14.20it/s]\n",
      "my bar!: 48it [00:03, 14.64it/s]\n",
      "my bar!: 52it [00:03, 15.04it/s]\n",
      "my bar!: 53it [00:03, 14.34it/s]\n",
      "my bar!: 57it [00:03, 15.56it/s]\n",
      "my bar!: 48it [00:03, 15.19it/s]\n",
      "my bar!: 51it [00:03, 15.86it/s]\n",
      "my bar!: 48it [00:03, 15.42it/s]\n",
      "my bar!: 48it [00:03, 15.78it/s]\n",
      "my bar!: 49it [00:03, 14.67it/s]\n",
      "my bar!: 58it [00:03, 15.35it/s]\n",
      "my bar!: 48it [00:03, 15.53it/s]\n",
      "my bar!: 56it [00:03, 14.59it/s]\n",
      "my bar!: 54it [00:03, 15.63it/s]\n",
      "my bar!: 55it [00:03, 15.42it/s]\n",
      "my bar!: 55it [00:03, 15.81it/s]\n",
      "my bar!: 48it [00:03, 15.24it/s]\n",
      "my bar!: 57it [00:03, 15.45it/s]\n",
      "my bar!: 48it [00:03, 15.41it/s]\n",
      "my bar!: 56it [00:03, 15.25it/s]\n",
      "my bar!: 55it [00:03, 15.68it/s]\n",
      "my bar!: 48it [00:03, 15.35it/s]\n",
      "my bar!: 48it [00:03, 15.72it/s]\n",
      "my bar!: 54it [00:03, 15.57it/s]\n",
      "my bar!: 57it [00:03, 14.85it/s]\n",
      "my bar!: 53it [00:03, 15.19it/s]\n",
      "my bar!: 48it [00:03, 15.50it/s]\n",
      "my bar!: 48it [00:03, 15.30it/s]\n",
      "my bar!: 52it [00:03, 15.01it/s]\n",
      "my bar!: 48it [00:03, 15.64it/s]\n",
      "my bar!: 56it [00:03, 15.43it/s]\n",
      "my bar!: 50it [00:03, 15.28it/s]\n",
      "my bar!: 48it [00:03, 15.57it/s]\n",
      "my bar!: 48it [00:03, 15.60it/s]\n",
      "my bar!: 50it [00:03, 15.30it/s]\n",
      "my bar!: 48it [00:03, 15.56it/s]\n",
      "my bar!: 48it [00:03, 15.56it/s]\n",
      "my bar!: 48it [00:03, 15.50it/s]\n",
      "my bar!: 55it [00:03, 14.68it/s]\n",
      "my bar!: 51it [00:03, 15.44it/s]\n",
      "my bar!: 57it [00:03, 15.45it/s]\n",
      "my bar!: 52it [00:03, 15.24it/s]\n",
      "my bar!: 51it [00:03, 15.36it/s]\n",
      "my bar!: 55it [00:03, 15.61it/s]\n",
      "my bar!: 54it [00:03, 15.41it/s]\n",
      "my bar!: 50it [00:03, 15.45it/s]\n",
      "my bar!: 54it [00:03, 15.16it/s]\n",
      "my bar!: 52it [00:03, 15.45it/s]\n",
      "my bar!: 48it [00:03, 15.59it/s]\n",
      "my bar!: 51it [00:03, 15.27it/s]\n",
      "my bar!: 54it [00:03, 14.93it/s]\n",
      "my bar!: 50it [00:03, 15.28it/s]\n",
      "my bar!: 48it [00:03, 15.14it/s]\n",
      "my bar!: 53it [00:03, 15.54it/s]\n",
      "my bar!: 58it [00:03, 15.54it/s]\n",
      "my bar!: 55it [00:03, 15.48it/s]\n",
      "my bar!: 48it [00:03, 15.13it/s]\n",
      "my bar!: 53it [00:03, 14.98it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 48it [00:03, 14.79it/s]\n",
      "my bar!: 48it [00:03, 14.40it/s]\n",
      "my bar!: 48it [00:03, 14.72it/s]\n",
      "my bar!: 49it [00:03, 13.92it/s]\n",
      "my bar!: 48it [00:03, 14.94it/s]\n",
      "my bar!: 48it [00:03, 15.65it/s]\n",
      "my bar!: 48it [00:03, 14.92it/s]\n",
      "my bar!: 53it [00:03, 14.24it/s]\n",
      "my bar!: 52it [00:03, 14.61it/s]\n",
      "my bar!: 48it [00:03, 14.01it/s]\n",
      "my bar!: 48it [00:03, 14.22it/s]\n",
      "my bar!: 56it [00:04, 13.84it/s]\n",
      "my bar!: 50it [00:03, 14.55it/s]\n",
      "my bar!: 48it [00:03, 13.79it/s]\n",
      "my bar!: 51it [00:03, 14.58it/s]\n",
      "my bar!: 49it [00:03, 15.12it/s]\n",
      "my bar!: 48it [00:03, 15.19it/s]\n",
      "my bar!: 48it [00:03, 15.89it/s]\n",
      "my bar!: 58it [00:03, 15.08it/s]\n",
      "my bar!: 48it [00:03, 15.59it/s]\n",
      "my bar!: 52it [00:03, 15.08it/s]\n",
      "my bar!: 48it [00:03, 15.40it/s]\n",
      "my bar!: 53it [00:03, 15.85it/s]\n",
      "my bar!: 48it [00:03, 15.42it/s]\n",
      "my bar!: 53it [00:03, 15.26it/s]\n",
      "my bar!: 48it [00:03, 14.92it/s]\n",
      "my bar!: 54it [00:03, 15.14it/s]\n",
      "my bar!: 48it [00:03, 15.31it/s]\n",
      "my bar!: 57it [00:03, 14.81it/s]\n",
      "my bar!: 48it [00:03, 15.07it/s]\n",
      "my bar!: 56it [00:03, 15.14it/s]\n",
      "my bar!: 50it [00:03, 15.36it/s]\n",
      "my bar!: 57it [00:03, 15.31it/s]\n",
      "my bar!: 56it [00:03, 15.28it/s]\n",
      "my bar!: 48it [00:03, 15.27it/s]\n",
      "my bar!: 48it [00:03, 15.15it/s]\n",
      "my bar!: 50it [00:03, 15.51it/s]\n",
      "my bar!: 61it [00:03, 15.35it/s]\n",
      "my bar!: 60it [00:03, 15.64it/s]\n",
      "my bar!: 51it [00:03, 15.55it/s]\n",
      "my bar!: 57it [00:03, 15.69it/s]\n",
      "my bar!: 55it [00:03, 15.70it/s]\n",
      "my bar!: 51it [00:03, 14.88it/s]\n",
      "my bar!: 48it [00:03, 15.39it/s]\n",
      "my bar!: 48it [00:03, 15.55it/s]\n",
      "my bar!: 48it [00:03, 15.39it/s]\n",
      "my bar!: 48it [00:03, 15.15it/s]\n",
      "my bar!: 48it [00:03, 15.17it/s]\n",
      "my bar!: 48it [00:03, 15.46it/s]\n",
      "my bar!: 57it [00:03, 14.70it/s]\n",
      "my bar!: 53it [00:03, 15.25it/s]\n",
      "my bar!: 48it [00:03, 15.37it/s]\n",
      "my bar!: 52it [00:03, 15.52it/s]\n",
      "my bar!: 48it [00:03, 15.34it/s]\n",
      "my bar!: 52it [00:03, 14.95it/s]\n",
      "my bar!: 48it [00:03, 15.14it/s]\n",
      "my bar!: 48it [00:03, 14.91it/s]\n",
      "my bar!: 52it [00:03, 15.26it/s]\n",
      "my bar!: 50it [00:03, 15.33it/s]\n",
      "my bar!: 54it [00:03, 15.32it/s]\n",
      "my bar!: 57it [00:03, 15.47it/s]\n",
      "my bar!: 48it [00:03, 15.59it/s]\n",
      "my bar!: 48it [00:03, 15.43it/s]\n",
      "my bar!: 58it [00:03, 15.21it/s]\n",
      "my bar!: 48it [00:03, 15.21it/s]\n",
      "my bar!: 48it [00:03, 15.57it/s]\n",
      "my bar!: 54it [00:03, 15.30it/s]\n",
      "my bar!: 50it [00:03, 15.14it/s]\n",
      "my bar!: 48it [00:03, 15.54it/s]\n",
      "my bar!: 52it [00:03, 14.83it/s]\n",
      "my bar!: 56it [00:03, 14.83it/s]\n",
      "my bar!: 53it [00:03, 14.25it/s]\n",
      "my bar!: 49it [00:03, 15.01it/s]\n",
      "my bar!: 51it [00:03, 14.13it/s]\n",
      "my bar!: 52it [00:03, 14.93it/s]\n",
      "my bar!: 48it [00:03, 14.69it/s]\n",
      "my bar!: 61it [00:04, 14.10it/s]\n",
      "my bar!: 52it [00:03, 14.69it/s]\n",
      "my bar!: 48it [00:03, 14.09it/s]\n",
      "my bar!: 56it [00:03, 15.42it/s]\n",
      "my bar!: 53it [00:03, 15.65it/s]\n",
      "my bar!: 60it [00:03, 15.71it/s]\n",
      "my bar!: 54it [00:03, 15.33it/s]\n",
      "my bar!: 48it [00:03, 15.70it/s]\n",
      "my bar!: 48it [00:03, 15.58it/s]\n",
      "my bar!: 56it [00:03, 15.50it/s]\n",
      "my bar!: 48it [00:03, 15.69it/s]\n",
      "my bar!: 53it [00:03, 15.24it/s]\n",
      "my bar!: 56it [00:03, 15.37it/s]\n",
      "my bar!: 51it [00:03, 14.79it/s]\n",
      "my bar!: 48it [00:03, 14.79it/s]\n",
      "my bar!: 56it [00:03, 15.09it/s]\n",
      "my bar!: 52it [00:03, 15.17it/s]\n",
      "my bar!: 52it [00:03, 15.23it/s]\n",
      "my bar!: 58it [00:03, 15.27it/s]\n",
      "my bar!: 56it [00:03, 15.21it/s]\n",
      "my bar!: 48it [00:03, 15.29it/s]\n",
      "my bar!: 55it [00:03, 15.86it/s]\n",
      "my bar!: 48it [00:03, 15.55it/s]\n",
      "my bar!: 58it [00:03, 15.61it/s]\n",
      "my bar!: 48it [00:03, 15.37it/s]\n",
      "my bar!: 56it [00:03, 15.42it/s]\n",
      "my bar!: 52it [00:03, 15.37it/s]\n",
      "my bar!: 48it [00:03, 15.78it/s]\n",
      "my bar!: 57it [00:03, 16.10it/s]\n",
      "my bar!: 52it [00:03, 14.88it/s]\n",
      "my bar!: 48it [00:03, 15.10it/s]\n",
      "my bar!: 50it [00:03, 14.24it/s]\n",
      "my bar!: 51it [00:03, 14.49it/s]\n",
      "my bar!: 48it [00:03, 15.06it/s]\n",
      "my bar!: 48it [00:03, 14.80it/s]\n",
      "my bar!: 48it [00:03, 15.10it/s]\n",
      "my bar!: 57it [00:03, 13.79it/s]\n",
      "my bar!: 48it [00:03, 14.45it/s]\n",
      "my bar!: 48it [00:03, 14.67it/s]\n",
      "my bar!: 48it [00:03, 15.00it/s]\n",
      "my bar!: 48it [00:03, 15.64it/s]\n",
      "my bar!: 56it [00:03, 15.74it/s]\n",
      "my bar!: 48it [00:03, 15.16it/s]\n",
      "my bar!: 48it [00:03, 15.16it/s]\n",
      "my bar!: 48it [00:03, 15.05it/s]\n",
      "my bar!: 49it [00:03, 15.64it/s]\n",
      "my bar!: 48it [00:03, 15.14it/s]\n",
      "my bar!: 60it [00:04, 14.79it/s]\n",
      "my bar!: 56it [00:03, 15.12it/s]\n",
      "my bar!: 48it [00:03, 14.58it/s]\n",
      "my bar!: 51it [00:03, 15.31it/s]\n",
      "my bar!: 48it [00:03, 14.75it/s]\n",
      "my bar!: 50it [00:03, 15.10it/s]\n",
      "my bar!: 50it [00:03, 15.07it/s]\n",
      "my bar!: 51it [00:03, 15.42it/s]\n",
      "my bar!: 48it [00:03, 14.90it/s]\n",
      "my bar!: 55it [00:03, 15.99it/s]\n",
      "my bar!: 48it [00:03, 14.72it/s]\n",
      "my bar!: 51it [00:03, 15.55it/s]\n",
      "my bar!: 59it [00:03, 15.00it/s]\n",
      "my bar!: 53it [00:03, 16.04it/s]\n",
      "my bar!: 48it [00:03, 15.81it/s]\n",
      "my bar!: 48it [00:03, 15.07it/s]\n",
      "my bar!: 48it [00:03, 15.36it/s]\n",
      "my bar!: 49it [00:03, 15.62it/s]\n",
      "my bar!: 53it [00:03, 16.02it/s]\n",
      "my bar!: 48it [00:03, 15.70it/s]\n",
      "my bar!: 48it [00:03, 15.52it/s]\n",
      "my bar!: 50it [00:03, 15.69it/s]\n",
      "my bar!: 48it [00:03, 15.10it/s]\n",
      "my bar!: 50it [00:03, 15.19it/s]\n",
      "my bar!: 56it [00:03, 14.67it/s]\n",
      "my bar!: 48it [00:03, 15.42it/s]\n",
      "my bar!: 56it [00:03, 15.31it/s]\n",
      "my bar!: 48it [00:03, 14.00it/s]\n",
      "my bar!: 48it [00:03, 14.31it/s]\n",
      "my bar!: 53it [00:03, 13.77it/s]\n",
      "my bar!: 48it [00:03, 13.64it/s]\n",
      "my bar!: 48it [00:03, 14.81it/s]\n",
      "my bar!: 48it [00:03, 14.27it/s]\n",
      "my bar!: 51it [00:03, 15.77it/s]\n",
      "my bar!: 48it [00:03, 15.26it/s]\n",
      "my bar!: 48it [00:03, 14.38it/s]\n",
      "my bar!: 48it [00:03, 14.39it/s]\n",
      "my bar!: 48it [00:03, 15.42it/s]\n"
     ]
    }
   ],
   "source": [
    "def explode_exp_info(row, maindf, userloc):\n",
    "    \"Explodes the information from each job and education cell. To be applied to each row of the experience dataframe\"\n",
    "    global max_edu, max_jobs\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    \n",
    "    for i in range(max_jobs):\n",
    "        row['JobExpDates{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpDesc{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpInstitution{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpInstitutionType{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpOverallTenure{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpTitle{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['JobExpTitleType{}_{}'.format(str(i),ghusername)] = None\n",
    "        \n",
    "    for i in range(max_edu):\n",
    "        row['EduExpDates{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpDesc{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpInstitution{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpInstitutionType{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpOverallTenure{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpTitle{}_{}'.format(str(i),ghusername)] = None\n",
    "        row['EduExpTitleType{}_{}'.format(str(i),ghusername)] = None  \n",
    "          \n",
    "       \n",
    "    for i in range(max_jobs):\n",
    "        if pd.notnull(row['JobExp{}_{}'.format(str(i),ghusername)]):\n",
    "            \n",
    "            row['JobExpDates{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['dates']\n",
    "            \n",
    "            row['JobExpDesc{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['desc']\n",
    "            \n",
    "            row['JobExpInstitution{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['institution']\n",
    "            \n",
    "            row['JobExpInstitutionType{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['institution_type']\n",
    "            \n",
    "            row['JobExpOverallTenure{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['tenure']\n",
    "            \n",
    "            row['JobExpTitle{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['title']\n",
    "            \n",
    "            row['JobExpTitleType{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['JobExp{}_{}'.format(str(i),ghusername)]['title_type']\n",
    "           \n",
    "        \n",
    "    for i in range(max_edu):\n",
    "            \n",
    "        if pd.notnull(row['EduExp{}_{}'.format(str(i),ghusername)]):\n",
    "\n",
    "            row['EduExpDates{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['dates']\n",
    "\n",
    "            row['EduExpDesc{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['desc']\n",
    "\n",
    "            row['EduExpInstitution{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['institution']\n",
    "\n",
    "            row['EduExpInstitutionType{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['institution_type']\n",
    "\n",
    "            row['EduExpOverallTenure{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['tenure']\n",
    "\n",
    "            row['EduExpTitle{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['title']\n",
    "\n",
    "            row['EduExpTitleType{}_{}'.format(str(i),ghusername)] = \\\n",
    "            row['EduExp{}_{}'.format(str(i),ghusername)]['title_type']\n",
    "            \n",
    "    return row\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "user_allexp = [user_allexp[i].progress_apply(explode_exp_info, args=(main_df,i), axis=1) for i in range(len(main_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving as took very long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T18:11:24.058573",
     "start_time": "2016-12-13T18:11:23.384772"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# _pickle.dump(user_allexp,open('tempuserallexp.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T18:43:02.613023",
     "start_time": "2016-12-13T18:43:01.768289"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_allexp = _pickle.load(open('tempuserallexp.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T18:43:05.247232",
     "start_time": "2016-12-13T18:43:04.356952"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding index as otherwise have issues with converting pandas objects\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print('Adding index as otherwise have issues with converting pandas objects')\n",
    "for i in range(len(main_df)):\n",
    "    user_allexp[i]['Index'] = user_allexp[i].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T18:52:57.065734",
     "start_time": "2016-12-13T18:43:13.568379"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_more_features(exp_df, maindf, userloc):\n",
    "    \"\"\"Extract more features - tenure, whether employed, in education, number of current job titles...\"\"\"\n",
    "    global max_jobs, max_edu\n",
    "\n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "\n",
    "    ts_index = exp_df.index\n",
    "\n",
    "    # Create tenure columns\n",
    "    for i in range(max_jobs):\n",
    "        exp_df['JobExpCurrentTenure{}_{}'.format(str(i), ghusername)] = np.nan\n",
    "        exp_df['JobExpCurrentTenure{}_{}'.format(str(\n",
    "            i), ghusername)] = exp_df['JobExpCurrentTenure{}_{}'.format(\n",
    "                str(i), ghusername)].astype(object)\n",
    "\n",
    "    # Calculate tenure for each job\n",
    "    for i in range(max_jobs):\n",
    "        for date in ts_index:\n",
    "            if np.any(\n",
    "                    pd.notnull(exp_df.ix[date, 'JobExpDates{}_{}'.format(\n",
    "                        str(i), ghusername)])):\n",
    "                exp_df.set_value(\n",
    "                    date,\n",
    "                    'JobExpCurrentTenure{}_{}'.format(str(i), ghusername),\n",
    "                    date - exp_df.\n",
    "                    ix[date, 'JobExpDates{}_{}'.format(str(i), ghusername)][0])\n",
    "                \n",
    "                \n",
    "    # Calculate number of jobs, education and total experiences at each date\n",
    "    \n",
    "    for date in ts_index:\n",
    "        exp_df.ix[date,'NumCurrentJobs_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('JobExpInstitution\\d', col)]].count())\n",
    "        \n",
    "        exp_df.ix[date,'NumCurrentEdu_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('EduExpInstitution\\d', col)]].count())\n",
    "        \n",
    "        exp_df.ix[date,'NumCurrentJobsAndEdu_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('EduExpInstitution\\d', col)]].count()) + \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('JobExpInstitution\\d', col)]].count())\n",
    "        \n",
    "    \n",
    "    # Create EmploymentStatus, EducationStatus, NEET Status\n",
    "    \n",
    "#     for date in ts_index:\n",
    "        if exp_df.ix[date,'NumCurrentJobs_{}'.format(ghusername)] == 0:\n",
    "            exp_df.ix[date,'EmploymentStatus_{}'.format(ghusername)] = 0\n",
    "        else:\n",
    "            exp_df.ix[date,'EmploymentStatus_{}'.format(ghusername)] = 1\n",
    "            \n",
    "#     for date in ts_index:\n",
    "        if exp_df.ix[date,'NumCurrentEdu_{}'.format(ghusername)] == 0:\n",
    "            exp_df.ix[date,'StudyingStatus_{}'.format(ghusername)] = 0\n",
    "        else:\n",
    "            exp_df.ix[date,'StudyingStatus_{}'.format(ghusername)] = 1\n",
    "            \n",
    "#     for date in ts_index:\n",
    "        if exp_df.ix[date,'NumCurrentJobsAndEdu_{}'.format(ghusername)] == 0:\n",
    "            exp_df.ix[date,'NEET_{}'.format(ghusername)] = 1\n",
    "        else:\n",
    "            exp_df.ix[date,'NEET_{}'.format(ghusername)] = 0\n",
    "            \n",
    "    \n",
    "    # Create a status flag for a new job and for an end of jobs\n",
    "    \n",
    "#     for date in ts_index:\n",
    "        exp_df.ix[date,'NewJobFlag_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('JobStart', col)]].count())\n",
    "        \n",
    "#     for date in ts_index:\n",
    "        exp_df.ix[date,'EndJobFlag_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('JobEnd', col)]].count())\n",
    "    \n",
    "#     for date in ts_index:\n",
    "        exp_df.ix[date,'StartEduFlag_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('EduStart', col)]].count())\n",
    "        \n",
    "#     for date in ts_index:\n",
    "        exp_df.ix[date,'EndEduFlag_{}'.format(ghusername)] = \\\n",
    "        int(exp_df.ix[date, [col for col in exp_df.columns if re.search('EduEnd', col)]].count())\n",
    "        \n",
    "\n",
    "    return exp_df\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "user_allexp = [get_more_features(user_allexp[i],main_df,i) for i in tqdm_notebook(range(len(main_df)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T18:54:44.077910",
     "start_time": "2016-12-13T18:54:43.163137"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save if works\n",
    "_pickle.dump(user_allexp,open('tempuserallexpv2.pkl','wb'))\n",
    "# user_allexp = _pickle.load(open('tempuserallexpv2.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T18:55:12.872688",
     "start_time": "2016-12-13T18:55:11.590782"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def cum_jobs_edu_todate(exp_df,maindf,userloc):\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    exp_df['CumJobsToDate_{}'.format(ghusername)] = exp_df['NewJobFlag_{}'.format(ghusername)].cumsum()\n",
    "    \n",
    "    exp_df['CumEduToDate_{}'.format(ghusername)] = exp_df['StartEduFlag_{}'.format(ghusername)].cumsum()\n",
    "    \n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Test to see if this works and doesn't break\n",
    "for i in tqdm_notebook(range(len(main_df))):   \n",
    "    cum_jobs_edu_todate(user_allexp[i],main_df,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T18:55:57.607558",
     "start_time": "2016-12-13T18:55:56.821480"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save if works\n",
    "_pickle.dump(user_allexp,open('tempuserallexpv3.pkl','wb'))\n",
    "# user_allexp = _pickle.load(open('tempuserallexpv3.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:01:40.355220",
     "start_time": "2016-12-13T18:56:22.634384"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def idenfify_highest_degree(exp_df,maindf,userloc):\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    ts_index = exp_df.index # to change back if doesn't work\n",
    "    \n",
    "    # Creates value to initialize best edu_rating\n",
    "    highest_edu_rating = 0\n",
    "    highest_degree = 'unknown'\n",
    "    highest_institution = 'unknown'\n",
    "    highest_institution_type = 'unknown'\n",
    "    highest_title = 'unknown'\n",
    "    \n",
    "\n",
    "    # Set the first value of the degree to minimum above before iteration\n",
    "    exp_df.ix[0,'HighestDegree_{}'.format(ghusername)] = highest_degree\n",
    "    exp_df.ix[0,'HighestInstitution_{}'.format(ghusername)] = highest_institution\n",
    "    exp_df.ix[0,'HighestInstitutionType_{}'.format(ghusername)] = highest_institution_type\n",
    "    exp_df.ix[0,'HighestDegreeDesc_{}'.format(ghusername)] = highest_title\n",
    "    exp_df.ix[0,'HighestDegreeStartDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'HighestDegreeEndDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'HighestDegreeTimeSinceStartDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'HighestDegreeTimeSinceEndDate_{}'.format(ghusername)] = None\n",
    "    \n",
    "    \n",
    "    # Iterate through each row and compare if a higher degree has been achieved\n",
    "    for i in range(len(ts_index)):\n",
    "        \n",
    "        # Ignore blank rows without new education status\n",
    "        if np.any(pd.notnull(exp_df.ix[i,'EduStart_{}'.format(ghusername)])):\n",
    "                    \n",
    "            # Iterate through each education item and update best if better than what is there\n",
    "            for edu in exp_df.ix[i,'EduStart_{}'.format(ghusername)]:\n",
    "                edu_rating = edu_points[edu['title_type']]\n",
    "                # Ignore equal education rating and only update if better\n",
    "                if edu_rating >= highest_edu_rating:\n",
    "                    highest_edu_rating = edu_rating\n",
    "                    highest_degree = edu['title_type']\n",
    "                    highest_institution = edu['institution']\n",
    "                    highest_institution_type = edu['institution_type']\n",
    "                    highest_title = edu['title']                    \n",
    "                    highest_degree_start_date = edu['dates'][0]\n",
    "                    highest_degree_end_date = edu['dates'][1]\n",
    "            \n",
    "            exp_df.ix[i,'HighestDegree_{}'.format(ghusername)] = highest_degree\n",
    "            exp_df.ix[i,'HighestInstitution_{}'.format(ghusername)] = highest_institution\n",
    "            exp_df.ix[i,'HighestInstitutionType_{}'.format(ghusername)] = highest_institution_type\n",
    "            exp_df.ix[i,'HighestDegreeDesc_{}'.format(ghusername)] = highest_title            \n",
    "            exp_df.ix[i,'HighestDegreeStartDate_{}'.format(ghusername)] = highest_degree_start_date\n",
    "            exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)] = highest_degree_end_date\n",
    "            \n",
    "            # Start date becomes relevant once entry is populated\n",
    "            exp_df.ix[i,'HighestDegreeTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "            exp_df.index[i] - exp_df.ix[i,'HighestDegreeStartDate_{}'.format(ghusername)]\n",
    "            \n",
    "            # End date only relevant once end date is smaller than the start date - test for that,\n",
    "            # otherwise stays none\n",
    "            \n",
    "            if exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)] < exp_df.index[i]:\n",
    "                exp_df.ix[i,'HighestDegreeTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.index[i] - exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)]\n",
    "            \n",
    "        else:\n",
    "            # Special case for first row\n",
    "            if i == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                # Set the degree to the previous value in the time series\n",
    "                exp_df.ix[i,'HighestDegree_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestDegree_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'HighestInstitution_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestInstitution_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'HighestInstitutionType_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestInstitutionType_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'HighestDegreeDesc_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestDegreeDesc_{}'.format(ghusername)]\n",
    "                                    \n",
    "                exp_df.ix[i,'HighestDegreeStartDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestDegreeStartDate_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'HighestDegreeEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "                if exp_df.ix[i-1,'HighestDegree_{}'.format(ghusername)] != 'unknown':\n",
    "                    exp_df.ix[i,'HighestDegreeTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "                    exp_df.index[i] - exp_df.ix[i,'HighestDegreeStartDate_{}'.format(ghusername)]\n",
    "                \n",
    "                    if exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)] < exp_df.index[i]:\n",
    "                        exp_df.ix[i,'HighestDegreeTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "                        exp_df.index[i] - exp_df.ix[i,'HighestDegreeEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "    \n",
    "    return exp_df\n",
    "        \n",
    "# ----------------------------------------------------------------\n",
    "    \n",
    "user_allexp = [idenfify_highest_degree(user_allexp[i],main_df,i) for i in tqdm_notebook(range(len(main_df)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:03:41.684135",
     "start_time": "2016-12-13T19:03:40.504741"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save if works\n",
    "_pickle.dump(user_allexp,open('tempuserallexpv4.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:23:24.290266",
     "start_time": "2016-12-13T19:23:22.089233"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_allexp = _pickle.load(open('tempuserallexpv4.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:23:18.515132",
     "start_time": "2016-12-13T19:23:18.499347"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def idenfify_bootcamps(exp_df,maindf,userloc):\n",
    "    \n",
    "#     ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "#     ts_index = exp_df.index # to change back if doesn't work\n",
    "    \n",
    "#     # Creates value to initialize best edu_rating\n",
    "#     bootcamp_degree = 'unknown'\n",
    "#     bootcamp_institution = 'unknown'\n",
    "#     bootcamp_title = 'unknown'\n",
    "#     bootcamp_start_date = None\n",
    "#     bootcamp_end_date = None\n",
    "    \n",
    "\n",
    "#     # Set the first value of the degree to minimum above before iteration\n",
    "#     exp_df.ix[0,'BootCamp_{}'.format(ghusername)] = bootcamp_degree\n",
    "#     exp_df.ix[0,'BootCampInstitution_{}'.format(ghusername)] = bootcamp_institution\n",
    "#     exp_df.ix[0,'BootCampDesc_{}'.format(ghusername)] = bootcamp_title\n",
    "#     exp_df.ix[0,'BootCampStartDate_{}'.format(ghusername)] = None\n",
    "#     exp_df.ix[0,'BootCampEndDate_{}'.format(ghusername)] = None\n",
    "#     exp_df.ix[0,'BootCampTimeSinceStartDate_{}'.format(ghusername)] = None\n",
    "#     exp_df.ix[0,'BootCampTimeSinceEndDate_{}'.format(ghusername)] = None\n",
    "    \n",
    "    \n",
    "#     # Iterate through each row and compare if a higher degree has been achieved\n",
    "#     for i in range(len(ts_index)):\n",
    "        \n",
    "#         # Ignore blank rows without new education status\n",
    "#         if np.any(pd.notnull(exp_df.ix[i,'EduStart_{}'.format(ghusername)])):\n",
    "                    \n",
    "#             # Iterate through each education item and update best if better than what is there\n",
    "#             for edu in exp_df.ix[i,'EduStart_{}'.format(ghusername)]:\n",
    "#                 if edu['institution_type'] == 'bootcamp' or edu['title_type'] == 'certificate':\n",
    "#                     bootcamp_degree = edu['title_type']\n",
    "#                     bootcamp_institution = edu['institution']\n",
    "#                     bootcamp_title = edu['title']                    \n",
    "#                     bootcamp_start_date = np.datetime64(edu['dates'][0])\n",
    "#                     bootcamp_end_date = np.datetime64(edu['dates'][1])\n",
    "            \n",
    "#                 exp_df.ix[i,'BootCamp_{}'.format(ghusername)] = bootcamp_degree\n",
    "#                 exp_df.ix[i,'BootCampInstitution_{}'.format(ghusername)] = bootcamp_institution\n",
    "#                 exp_df.ix[i,'BootCampDesc_{}'.format(ghusername)] = bootcamp_title            \n",
    "#                 exp_df.ix[i,'BootCampDegreeStartDate_{}'.format(ghusername)] = bootcamp_start_date\n",
    "#                 exp_df.ix[i,'BootCampDegreeEndDate_{}'.format(ghusername)] = bootcamp_end_date\n",
    "            \n",
    "#             # Start date becomes relevant once entry is populated\n",
    "#             exp_df.ix[i,'BootCampTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "#             exp_df.index[i] - exp_df.ix[i,'BootCampStartDate_{}'.format(ghusername)]\n",
    "            \n",
    "#             # End date only relevant once end date is smaller than the start date - test for that,\n",
    "#             # otherwise stays none\n",
    "            \n",
    "#             if exp_df.ix[i,'BootCampEndDate_{}'.format(ghusername)] < exp_df.index[i]:\n",
    "#                 exp_df.ix[i,'BootCampTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "#                 exp_df.index[i] - exp_df.ix[i,'BootCampEndDate_{}'.format(ghusername)]\n",
    "            \n",
    "#         else:\n",
    "#             # Special case for first row\n",
    "#             if i == 0:\n",
    "#                 pass\n",
    "            \n",
    "#             else:\n",
    "#                 # Set the degree to the previous value in the time series\n",
    "#                 exp_df.ix[i,'BootCamp_{}'.format(ghusername)] = \\\n",
    "#                 exp_df.ix[i-1,'BootCamp_{}'.format(ghusername)]\n",
    "\n",
    "#                 exp_df.ix[i,'BootCampInstitution_{}'.format(ghusername)] = \\\n",
    "#                 exp_df.ix[i-1,'BootCampInstitution_{}'.format(ghusername)]\n",
    "\n",
    "#                 exp_df.ix[i,'BootCampDegreeDesc_{}'.format(ghusername)] = \\\n",
    "#                 exp_df.ix[i-1,'BootCampDegreeDesc_{}'.format(ghusername)]\n",
    "                                    \n",
    "#                 exp_df.ix[i,'BootCampStartDate_{}'.format(ghusername)] = \\\n",
    "#                 exp_df.ix[i-1,'BootCampStartDate_{}'.format(ghusername)]\n",
    "\n",
    "#                 exp_df.ix[i,'BootCampEndDate_{}'.format(ghusername)] = \\\n",
    "#                 exp_df.ix[i-1,'BootCampEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "#                 if exp_df.ix[i-1,'BootCamp_{}'.format(ghusername)] != 'unknown':\n",
    "#                     exp_df.ix[i,'BootCampTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "#                     exp_df.index[i] - exp_df.ix[i,'BootCampStartDate_{}'.format(ghusername)]\n",
    "                \n",
    "#                     if exp_df.ix[i,'BootCampEndDate_{}'.format(ghusername)] < exp_df.index[i]:\n",
    "#                         exp_df.ix[i,'BootCampTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "#                         exp_df.index[i] - exp_df.ix[i,'BootCampEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "    \n",
    "#     return exp_df\n",
    "\n",
    "# user_allexp = [idenfify_bootcamps(user_allexp[i],main_df,i) for i in tqdm_notebook(range(len(main_df)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:29:16.657857",
     "start_time": "2016-12-13T19:23:43.798000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idenfify_recent_job(exp_df,maindf,userloc):\n",
    "    \n",
    "    ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    ts_index = exp_df['Index']\n",
    "    \n",
    "    # Creates value to initialize best edu_rating\n",
    "    recent_job = 'unknown'\n",
    "    recent_institution = 'unknown'\n",
    "    recent_institution_type = 'unknown'\n",
    "    recent_title = 'unknown'\n",
    "    recent_title_type = 'unknown'\n",
    "    \n",
    "\n",
    "    # Set the first value of the degree to minimum above before iteration\n",
    "    exp_df.ix[0,'RecentJob_{}'.format(ghusername)] = recent_job\n",
    "    exp_df.ix[0,'RecentJobInstitution_{}'.format(ghusername)] = recent_institution\n",
    "    exp_df.ix[0,'RecentJobInstitutionType_{}'.format(ghusername)] = recent_institution_type\n",
    "    exp_df.ix[0,'RecentJobDesc_{}'.format(ghusername)] = recent_title\n",
    "    exp_df.ix[0,'RecentJobStartDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'RecentJobEndDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'RecentJobTimeSinceStartDate_{}'.format(ghusername)] = None\n",
    "    exp_df.ix[0,'RecentJobTimeSinceEndDate_{}'.format(ghusername)] = None\n",
    "    \n",
    "    \n",
    "    # Iterate through each row and compare if a more recent job has been started\n",
    "    for i in range(len(ts_index)):\n",
    "        \n",
    "        # Ignore blank rows without new job status\n",
    "        if np.any(pd.notnull(exp_df.ix[i,'JobStart_{}'.format(ghusername)])):\n",
    "                    \n",
    "            # Iterate through each education item and update best if better than what is there\n",
    "            for job in exp_df.ix[i,'JobStart_{}'.format(ghusername)]:\n",
    "                job_date = job['dates'][0]\n",
    "                # Ignore equal education rating and only update if better\n",
    "                if job_date >= ts_index[0]:\n",
    "                    recent_job = job['title_type']\n",
    "                    recent_institution = job['institution']\n",
    "                    recent_institution_type = job['institution_type']\n",
    "                    recent_title = job['title']                    \n",
    "                    recent_job_start_date = job['dates'][0]\n",
    "                    recent_job_end_date = job['dates'][1]\n",
    "            \n",
    "            exp_df.ix[i,'RecentJob_{}'.format(ghusername)] = recent_job\n",
    "            exp_df.ix[i,'RecentJobInstitution_{}'.format(ghusername)] = recent_institution\n",
    "            exp_df.ix[i,'RecentJobInstitutionType_{}'.format(ghusername)] = recent_institution_type\n",
    "            exp_df.ix[i,'RecentJobDesc_{}'.format(ghusername)] = recent_title            \n",
    "            exp_df.ix[i,'RecentJobStartDate_{}'.format(ghusername)] = recent_job_start_date\n",
    "            exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)] = recent_job_end_date\n",
    "            \n",
    "            # Start date becomes relevant once entry is populated\n",
    "            exp_df.ix[i,'RecentJobTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "            exp_df.ix[i,'Index'] - exp_df.ix[i,'RecentJobStartDate_{}'.format(ghusername)]\n",
    "            \n",
    "            # End date only relevant once end date is smaller than the start date - test for that,\n",
    "            # otherwise stays none\n",
    "            \n",
    "            if exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)] < exp_df.ix[i,'Index']:\n",
    "                exp_df.ix[i,'RecentJobTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i,'Index'] - exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)]\n",
    "            \n",
    "        else:\n",
    "            # Special case for first row\n",
    "            if i == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                # Set the degree to the previous value in the time series\n",
    "                exp_df.ix[i,'RecentJob_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJob_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'RecentJobInstitution_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobInstitution_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'RecentJobInstitutionType_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobInstitutionType_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'RecentJobDesc_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobDesc_{}'.format(ghusername)]\n",
    "                                    \n",
    "                exp_df.ix[i,'RecentJobStartDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobStartDate_{}'.format(ghusername)]\n",
    "\n",
    "                exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)] = \\\n",
    "                exp_df.ix[i-1,'RecentJobEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "                if exp_df.ix[i-1,'RecentJob_{}'.format(ghusername)] != 'unknown':\n",
    "                    exp_df.ix[i,'RecentJobTimeSinceStartDate_{}'.format(ghusername)] = \\\n",
    "                    exp_df.ix[i,'Index'] - exp_df.ix[i,'RecentJobStartDate_{}'.format(ghusername)]\n",
    "                \n",
    "                    if exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)] < exp_df.index[i]:\n",
    "                        exp_df.ix[i,'RecentJobTimeSinceEndDate_{}'.format(ghusername)] = \\\n",
    "                        exp_df.ix[i,'Index'] - exp_df.ix[i,'RecentJobEndDate_{}'.format(ghusername)]\n",
    "                \n",
    "    \n",
    "    return exp_df\n",
    "        \n",
    "# ----------------------------------------------------------------\n",
    "    \n",
    "user_allexp = [idenfify_recent_job(user_allexp[i],main_df,i) for i in tqdm_notebook(range(len(main_df)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:30:08.281077",
     "start_time": "2016-12-13T19:30:06.604793"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save if works\n",
    "_pickle.dump(user_allexp,open('tempuserallexpv5.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:41:58.614251",
     "start_time": "2016-12-13T19:41:56.249250"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_allexp = _pickle.load(open('tempuserallexpv5.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:42:18.865789",
     "start_time": "2016-12-13T19:42:18.860235"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_min_max_tenure(row,maindf,userloc):\n",
    "#     \"\"\"Get the minimum tenure of the most recent job - If very low, unlikely to be looking for job\"\"\"\n",
    "#     ghusername = maindf['inferred_ghuser_copy'].iloc[userloc]\n",
    "    \n",
    "#     relevantcols = [col for col in row.index if 'JobExpCurrentTenure' in col]\n",
    "    \n",
    "#     # Factor to divide result by to get result in days\n",
    "#     divfactor = 3600*24*1000000000\n",
    "    \n",
    "#     if pd.isnull(row[relevantcols].values.any()):\n",
    "#         row['MinJobTenure_{}'.format(ghusername)] = 0\n",
    "#         row['MaxJobTenure_{}'.format(ghusername)] = 0\n",
    "#         row['MeanJobTenure_{}'.format(ghusername)] = 0\n",
    "    \n",
    "#     else:\n",
    "#         row['MinJobTenure_{}'.format(ghusername)] = \\\n",
    "#         min([item for item in row[relevantcols] if pd.notnull(item)])/divfactor\n",
    "        \n",
    "#         row['MaxJobTenure_{}'.format(ghusername)] = \\\n",
    "#         max([item for item in row[relevantcols] if pd.notnull(item)])/divfactor\n",
    "        \n",
    "#         row['MeanJobTenure_{}'.format(ghusername)] = \\\n",
    "#         np.mean([item for item in row[relevantcols] if pd.notnull(item)])/divfactor\n",
    "        \n",
    "#     return row\n",
    "\n",
    "# # ----------------------------------------------------------------    \n",
    "\n",
    "# user_allexp = [user_allexp[i].apply(get_min_max_tenure,args=(main_df,i),axis=1) \\\n",
    "#                for i in tqdm_notebook(range(len(main_df)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:42:23.132768",
     "start_time": "2016-12-13T19:42:22.450141"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_allexp = [user_allexp[i].drop('Index', axis=1) for i in tqdm_notebook(range(len(main_df)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:46:40.088569",
     "start_time": "2016-12-13T19:46:39.067284"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save if works\n",
    "_pickle.dump(user_allexp,open('tempuserallexpv6.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:58:33.166707",
     "start_time": "2016-12-13T19:58:30.275508"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# user_allexp = _pickle.load(open('tempuserallexpv6.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T18:55:21.690020",
     "start_time": "2016-12-11T18:55:21.687815"
    }
   },
   "source": [
    "## 2.4 Adding All Info from Main Dataframe to TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:58:55.617840",
     "start_time": "2016-12-13T19:58:42.740340"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def add_maindfinfo(df,loc):\n",
    "    \n",
    "    user_data = pd.DataFrame(main_df[[\n",
    "    'linkedin_name', 'name', 'contact', 'gh_acct_created_at', 'updated_at',\n",
    "    'followers', 'following', 'hireable', 'email', 'inferred_ghuser_copy',\n",
    "    'login', 'github_account', 'hn_username', 'location_hn',\n",
    "    'linkedin_location', 'location_gh', 'company', 'remote', 'can_relocate',\n",
    "    'stack', 'resume', 'links', 'text', 'body', 'bio', 'blog', 'public_gists',\n",
    "    'public_repos'\n",
    "            ]].iloc[loc,:]).transpose()\n",
    "    \n",
    "    user_data['old_index'] = user_data.index\n",
    "    \n",
    "    username = df['inferred_ghuser_copy'].iloc[loc]\n",
    "    \n",
    "    user_data = user_data.rename(columns={'linkedin_name':'LinkedInName_{}'.format(username),\n",
    "                           'name': 'Name_{}'.format(username),\n",
    "                           'contact': 'Contact_{}'.format(username),\n",
    "                           'gh_acct_created_at': 'GHAcctCreatedAt_{}'.format(username),\n",
    "                           'updated_at': 'GHAcctUpdatedAt_{}'.format(username),\n",
    "                           'followers': 'GHFollowers_{}'.format(username),\n",
    "                           'following': 'GHFollowing_{}'.format(username),\n",
    "                           'hireable': 'GHHireable_{}'.format(username),\n",
    "                           'email': 'Email_{}'.format(username) ,\n",
    "                           'inferred_ghuser_copy': 'InferredGHUserCopy_{}'.format(username) ,\n",
    "                           'login': 'GHLogin_{}'.format(username),\n",
    "                           'github_account': 'GHAcct_{}'.format(username),\n",
    "                           'hn_username': 'HNUsername_{}'.format(username),\n",
    "                           'location_hn': 'HNLocation_{}'.format(username),\n",
    "                           'linkedin_location': 'LinkedInLocation_{}'.format(username),\n",
    "                           'location_gh': 'GHLocation_{}'.format(username),\n",
    "                           'company': 'GHCompany_{}'.format(username),\n",
    "                           'remote': 'Remote_{}'.format(username),\n",
    "                           'can_relocate': 'CanRelocate_{}'.format(username),\n",
    "                           'stack': 'Stack_{}'.format(username),\n",
    "                           'resume': 'Resume_{}'.format(username),\n",
    "                           'links': 'Links_{}'.format(username),\n",
    "                           'text': 'Text_{}'.format(username),\n",
    "                           'body': 'Body_{}'.format(username),\n",
    "                           'bio': 'Bio_{}'.format(username),\n",
    "                           'blog': 'Blog_{}'.format(username),\n",
    "                           'public_gists': 'PublicGists_{}'.format(username),\n",
    "                           'public_repos': 'PublicRepos_{}'.format(username),\n",
    "                           'old_index': 'OldIndex_{}'.format(username)             \n",
    "                          })\n",
    "    \n",
    "    user_data.index = [np.datetime64('2013-12-31')]\n",
    "    date_index = pd.date_range('01/31/2013', periods=49, freq='M')\n",
    "    user_data = pd.concat([user_data]*49)\n",
    "    user_data.index = date_index\n",
    "    \n",
    "    return user_data\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "user_datas = [add_maindfinfo(main_df,i) for i in tqdm_notebook(range(len(main_df)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:59:09.099943",
     "start_time": "2016-12-13T19:59:05.010883"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_datas_merged = [pd.concat([user_allexp[i],user_datas[i]], axis = 1) for i in tqdm_notebook(range(len(main_df)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:59:33.493561",
     "start_time": "2016-12-13T19:59:31.308492"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save if works\n",
    "_pickle.dump(user_datas_merged,open('tempuserallexpv7.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:59:39.890497",
     "start_time": "2016-12-13T19:59:38.912069"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def amend_cols(df):\n",
    "    df.columns = df.columns.str.split('_', expand=True)\n",
    "    \n",
    "for i in tqdm_notebook(range(len(main_df))):\n",
    "    amend_cols(user_datas_merged[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:59:51.150584",
     "start_time": "2016-12-13T19:59:47.236880"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save if works\n",
    "_pickle.dump(user_datas_merged,open('tempmergeduserdata.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T19:59:55.123140",
     "start_time": "2016-12-13T19:59:54.447987"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_datas = [df.reorder_levels([1,0], axis=1) for df in user_datas_merged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T20:01:33.363525",
     "start_time": "2016-12-13T20:01:32.411295"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_datas = [df[(df.index > min_date) & (df.index < max_date)] for df in user_datas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Saving Dataframe for processing by next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T20:02:24.023004",
     "start_time": "2016-12-13T20:02:22.557032"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file to /Users/Toavina/githubdata/12.charting_and_modelling/1.pickles/merged_df.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Saving file to '+savefile_path)\n",
    "_pickle.dump(user_datas, open(savefile_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T20:03:08.980279",
     "start_time": "2016-12-13T20:03:08.976069"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savefile_path_concat = join('/Users/','Toavina','githubdata','12.charting_and_modelling','1.pickles','merged_df_concat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T20:04:05.618492",
     "start_time": "2016-12-13T20:04:02.733417"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_user_datas = pd.concat(user_datas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T20:06:12.627616",
     "start_time": "2016-12-13T20:06:12.620857"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_user_datas['linus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-13T20:07:15.591016",
     "start_time": "2016-12-13T20:07:14.277014"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving concatenated DF to /Users/Toavina/githubdata/12.charting_and_modelling/1.pickles/merged_df_concat.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Saving concatenated DF to '+savefile_path_concat)\n",
    "_pickle.dump(concat_user_datas, open(savefile_path_concat, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
