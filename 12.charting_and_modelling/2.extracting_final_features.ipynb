{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T23:18:37.528823",
     "start_time": "2016-12-11T23:18:29.752266"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dataframe and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T23:19:22.392763",
     "start_time": "2016-12-11T23:19:21.342731"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main dataframe with aggregated Linkedin, Github and Hacker News data\n"
     ]
    }
   ],
   "source": [
    "print('Loading main dataframe with aggregated Linkedin, Github and Hacker News data')\n",
    "\n",
    "inputfile_path = join('/Users/','Toavina','githubdata','11.getting_linkedin_data','4.pickles','merged_dfv2.pkl')\n",
    "\n",
    "user_dfs = _pickle.load(open(inputfile_path,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract last job, last edu, last exp, tenure at last job, edu, exp, title, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T23:23:02.994654",
     "start_time": "2016-12-11T23:23:02.990169"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = user_dfs[0]['linus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T23:23:14.008596",
     "start_time": "2016-12-11T23:23:14.004002"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreateEvent', 'PushEvent', 'GollumEvent',\n",
       "       'PullRequestReviewCommentEvent', 'DeleteEvent', 'PullRequestEvent',\n",
       "       'GistEvent', 'PublicEvent', 'AggEventsEqual', 'AggEventsWeighted',\n",
       "       'HNPosts', 'JobStart', 'JobEnd', 'EduStart', 'EduEnd', 'ExpStart',\n",
       "       'ExpEnd', 'LinkedInName', 'Name', 'Contact', 'GHAcctCreatedAt',\n",
       "       'GHAcctUpdatedAt', 'GHFollowers', 'GHFollowing', 'GHHireable', 'Email',\n",
       "       'InferredGHUserCopy', 'GHLogin', 'GHAcct', 'HNUsername', 'HNLocation',\n",
       "       'LinkedInLocation', 'GHLocation', 'GHCompany', 'Remote', 'CanRelocate',\n",
       "       'Stack', 'Resume', 'Links', 'Text', 'Body', 'Bio', 'Blog',\n",
       "       'PublicGists', 'PublicRepos', 'OldIndex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T23:51:52.432746",
     "start_time": "2016-12-11T23:51:52.424651"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?pd.Series.fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-11T23:54:21.858786",
     "start_time": "2016-12-11T23:54:21.801073"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Toavina/anaconda/envs/python3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "sample['MostRecentJob'] = sample.loc[:,'JobStart'].fillna(method='pad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fill forward job start to get most recent job started (allow space for 2 or three)\n",
    "* Create a column to check whether employed or not, and if so, calculate tenure (make NA, then fill forward)\n",
    "\n",
    "* Expand most recent job started to include type... per diagram\n",
    "\n",
    "* Do the same with education\n",
    "\n",
    "* Do the same with the aggregate column\n",
    "\n",
    "* Make sure that all the relevant columns are showing for modelling\n",
    "\n",
    "* Redo charting function with previous package\n",
    "\n",
    "* Create anomalies for each timeseries\n",
    "\n",
    "* Create column to check accuracy of anomalies for various thresholds to pick the right level\n",
    "\n",
    "* Pick rows with anomalies - create a separate dataframe for that with x previous months\n",
    "\n",
    "* Classify anomalies based on points system\n",
    "\n",
    "* Run a model to identify this and check accuracy\n",
    "\n",
    "* Find key factors \n",
    "\n",
    "* Write presentation"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
