{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I refined my search to limit number of users, this script will allow the updating of the users to download, removing those already downloaded remotely.\n",
    "\n",
    "On another note, I realised that having so many files is not great, so it may be better on the GH script to merge all the files into pandas frames (TBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load global list of users to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_userlist = np.array(pd.read_csv('1.data/ghuserstodl000000000000.csv')['actor_login'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the global list of users to download is 1995284 users\n"
     ]
    }
   ],
   "source": [
    "print('The length of the global list of users to download is ' + str(len(global_userlist)) +' users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(global_userlist, open('2.pickles/global_userlist.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load list of files already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "already_dl = np.array([f[:len(f)-5] for f in listdir('1.data/user_data') if isfile(join('1.data/user_data',f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "already_dl2 = np.array([f[:len(f)-5] for f in listdir('1.data/user_data1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "already_dl3 = np.array([f[:len(f)-5] for f in listdir('1.data/user_data2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dls = np.concatenate((already_dl,already_dl2,already_dl3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check complete - userlist for all downloads has the same length as its constituents\n"
     ]
    }
   ],
   "source": [
    "if len(all_dls) == len(already_dl) + len(already_dl2) + len(already_dl3):\n",
    "    print('Check complete - userlist for all downloads has the same length as its constituents')\n",
    "else:\n",
    "    print('Error - Userlist for all downloads does not have the same length as its constituents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far 1005995 users have been downloaded\n"
     ]
    }
   ],
   "source": [
    "print('So far '+ str(len(all_dls)) + ' users have been downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return a matrix of files to download that does not contain already downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing a revised list of users to download that excludes those already downloaded\n"
     ]
    }
   ],
   "source": [
    "print('\\nComputing a revised list of users to download that excludes those already downloaded')\n",
    "remaining_DLs = np.setdiff1d(global_userlist, all_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1019157 users left to download\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(len(remaining_DLs)) +' users left to download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(remaining_DLs, open('2.pickles/updateduserlist.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a list of already downloaded users within the latest global user list\n",
    "already_dl = np.intersect1d(global_userlist,all_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 976127 users on the global list that have already been downloaded\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(len(already_dl)) +' users on the global list that have already been downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(already_dl, open('2.pickles/latestusersalreadydownloaded.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate time it would take to download remaining users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_requests = 5000\n",
    "time_to_dl = 1 # in minutes\n",
    "delay_between_requests = 60 + time_to_dl # minutes\n",
    "total_for_each_chunk = time_to_dl + delay_between_requests\n",
    "adjustment = 0 # Adjust for other downloads not mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks = math.ceil((len(remaining_DLs)-adjustment) / max_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_time = chunks * total_for_each_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_in_hours = total_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_in_days = time_in_hours / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I estimate that it would take 8.8 days to download the data with one instance\n"
     ]
    }
   ],
   "source": [
    "print('\\nI estimate that it would take ' + str(round(time_in_days,1)) + ' days to download the data' + \\\n",
    "                                               ' with one instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following is an estimate of how long the download would take with up to 5 instances\n",
      "1 instance: 8.8 days\n",
      "2 instance: 4.4 days\n",
      "3 instance: 2.9 days\n",
      "4 instance: 2.2 days\n",
      "5 instance: 1.8 days\n",
      "6 instance: 1.5 days\n",
      "7 instance: 1.3 days\n",
      "8 instance: 1.1 days\n",
      "9 instance: 1.0 days\n",
      "10 instance: 0.9 days\n",
      "11 instance: 0.8 days\n",
      "12 instance: 0.7 days\n",
      "13 instance: 0.7 days\n",
      "14 instance: 0.6 days\n",
      "15 instance: 0.6 days\n",
      "16 instance: 0.5 days\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe following is an estimate of how long the download would take with up to 5 instances')\n",
    "for i in range(1,17):\n",
    "    print(str(i)+' instance: '+ str(round(time_in_days/i,1)) + ' days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split remaining downloads into 8 chunks so can download on 8 different instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remaining_DL_to_split = np.array_split(remaining_DLs, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dl1 = remaining_DL_to_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl2 = remaining_DL_to_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl3 = remaining_DL_to_split[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dl4 = remaining_DL_to_split[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl5 = remaining_DL_to_split[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl6 = remaining_DL_to_split[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl7 = remaining_DL_to_split[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl8 = remaining_DL_to_split[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The consistuent arrays completely cover all remaining downloads\n"
     ]
    }
   ],
   "source": [
    "if(len(remaining_DLs) == len(dl1) + \\\n",
    "len(dl2) + len(dl3) + len(dl4) + \\\n",
    "len(dl5) + len(dl6) + len(dl7) + len(dl8)):\n",
    "    print('The consistuent arrays completely ' +\\\n",
    "          'cover all remaining downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dl_lists = [dl1,dl2,dl3,dl4,dl5,dl6,dl7,dl8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127395\n",
      "127395\n",
      "127395\n",
      "127395\n",
      "127395\n",
      "127394\n",
      "127394\n",
      "127394\n"
     ]
    }
   ],
   "source": [
    "for each in all_dl_lists:\n",
    "    print(len(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(dl1, open('2.pickles/userlist_1of8.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dl2, open('2.pickles/userlist_2of8.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dl3, open('2.pickles/userlist_3of8.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dl4, open('2.pickles/userlist_4of8.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dl5, open('2.pickles/userlist_5of8.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dl6, open('2.pickles/userlist_6of8.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dl7, open('2.pickles/userlist_7of8.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dl8, open('2.pickles/userlist_8of8.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019157"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(127395)*5 + 3*127394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1019157-1018986"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
